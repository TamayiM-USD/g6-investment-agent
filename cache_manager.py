"""
Disk-based caching system for API clients
Reduces redundant API calls while preserving access to real data

NOTE: LLM USAGE
This code was generated by an AI language model (ChatGPT) to assist in development.
It is intended to be reviewed and tested before production use.
"""

import json
import hashlib
import os
import time
from pathlib import Path
from typing import Any, Callable, Dict, Optional
from functools import wraps
from datetime import datetime, timedelta


class CacheManager:
    """Manages disk-based caching for API responses"""

    # Default TTL values (in seconds) per client
    DEFAULT_TTL = {
        "Yahoo Finance": 3600,      # 1 hour - market data changes frequently
        "Alpha Vantage": 86400,     # 24 hours - maximize 25/day limit
        "FRED": 604800,             # 7 days - economic data updates slowly
        "SEC EDGAR": 2592000,       # 30 days - filings are historical
        "default": 3600             # 1 hour fallback
    }

    def __init__(self, cache_dir: str = ".api_cache"):
        """
        Initialize cache manager

        Args:
            cache_dir: Directory to store cache files
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self._stats = {"hits": 0, "misses": 0, "errors": 0}

    def _generate_cache_key(self, client_name: str, method_name: str,
                           args: tuple, kwargs: dict) -> str:
        """
        Generate unique cache key from function call parameters

        Args:
            client_name: Name of the API client
            method_name: Name of the method being called
            args: Positional arguments
            kwargs: Keyword arguments

        Returns:
            SHA256 hash as cache key
        """
        # Create deterministic string representation
        key_parts = [
            client_name,
            method_name,
            str(args),
            str(sorted(kwargs.items()))
        ]
        key_string = "|".join(key_parts)

        # Generate hash
        return hashlib.sha256(key_string.encode()).hexdigest()

    def _get_cache_path(self, cache_key: str, client_name: str) -> Path:
        """Get file path for cache entry"""
        # Organize by client for easier management
        client_dir = self.cache_dir / client_name.replace(" ", "_")
        client_dir.mkdir(exist_ok=True)
        return client_dir / f"{cache_key}.json"

    def get(self, cache_key: str, client_name: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve cached data if valid

        Args:
            cache_key: Cache key hash
            client_name: Name of the API client

        Returns:
            Cached data dict or None if not found/expired
        """
        cache_path = self._get_cache_path(cache_key, client_name)

        if not cache_path.exists():
            self._stats["misses"] += 1
            return None

        try:
            with open(cache_path, 'r') as f:
                cache_entry = json.load(f)

            # Check expiry
            expiry_time = cache_entry.get("expiry_timestamp")
            if expiry_time and time.time() > expiry_time:
                # Cache expired
                cache_path.unlink()  # Remove expired cache
                self._stats["misses"] += 1
                return None

            self._stats["hits"] += 1
            return cache_entry.get("data")

        except (json.JSONDecodeError, IOError) as e:
            self._stats["errors"] += 1
            print(f"Cache read error: {e}")
            return None

    def set(self, cache_key: str, client_name: str, data: Any,
            ttl: Optional[int] = None) -> None:
        """
        Store data in cache

        Args:
            cache_key: Cache key hash
            client_name: Name of the API client
            data: Data to cache
            ttl: Time-to-live in seconds (uses default if None)
        """
        cache_path = self._get_cache_path(cache_key, client_name)

        # Use client-specific TTL or default
        if ttl is None:
            ttl = self.DEFAULT_TTL.get(client_name, self.DEFAULT_TTL["default"])

        cache_entry = {
            "data": data,
            "cached_at": time.time(),
            "cached_at_readable": datetime.now().isoformat(),
            "expiry_timestamp": time.time() + ttl,
            "expiry_readable": (datetime.now() + timedelta(seconds=ttl)).isoformat(),
            "client": client_name,
            "ttl_seconds": ttl
        }

        try:
            with open(cache_path, 'w') as f:
                json.dump(cache_entry, f, indent=2, default=str)
        except (IOError, TypeError) as e:
            self._stats["errors"] += 1
            print(f"Cache write error: {e}")

    def clear_client_cache(self, client_name: str) -> int:
        """
        Clear all cache entries for a specific client

        Args:
            client_name: Name of the API client

        Returns:
            Number of cache files deleted
        """
        client_dir = self.cache_dir / client_name.replace(" ", "_")
        if not client_dir.exists():
            return 0

        count = 0
        for cache_file in client_dir.glob("*.json"):
            cache_file.unlink()
            count += 1

        return count

    def clear_all_cache(self) -> int:
        """
        Clear entire cache

        Returns:
            Number of cache files deleted
        """
        count = 0
        for cache_file in self.cache_dir.rglob("*.json"):
            cache_file.unlink()
            count += 1

        return count

    def clear_expired(self) -> int:
        """
        Remove expired cache entries

        Returns:
            Number of expired entries removed
        """
        count = 0
        current_time = time.time()

        for cache_file in self.cache_dir.rglob("*.json"):
            try:
                with open(cache_file, 'r') as f:
                    cache_entry = json.load(f)

                expiry = cache_entry.get("expiry_timestamp")
                if expiry and current_time > expiry:
                    cache_file.unlink()
                    count += 1

            except (json.JSONDecodeError, IOError):
                # Remove corrupted cache files
                cache_file.unlink()
                count += 1

        return count

    def get_stats(self) -> Dict[str, Any]:
        """
        Get cache statistics

        Returns:
            Dict with hits, misses, errors, and hit rate
        """
        total = self._stats["hits"] + self._stats["misses"]
        hit_rate = (self._stats["hits"] / total * 100) if total > 0 else 0

        return {
            "hits": self._stats["hits"],
            "misses": self._stats["misses"],
            "errors": self._stats["errors"],
            "hit_rate_percent": round(hit_rate, 2),
            "total_requests": total
        }

    def get_cache_info(self) -> Dict[str, Any]:
        """
        Get information about cached data

        Returns:
            Dict with cache size, file count, etc.
        """
        total_files = 0
        total_size = 0
        clients = {}

        for cache_file in self.cache_dir.rglob("*.json"):
            total_files += 1
            total_size += cache_file.stat().st_size

            # Get client name from directory
            client_name = cache_file.parent.name.replace("_", " ")
            clients[client_name] = clients.get(client_name, 0) + 1

        return {
            "total_entries": total_files,
            "total_size_bytes": total_size,
            "total_size_kb": round(total_size / 1024, 2),
            "entries_by_client": clients,
            "cache_directory": str(self.cache_dir)
        }


# Global cache instance
_cache_manager = CacheManager()


def cache_response(client_name: str, ttl: Optional[int] = None,
                   enabled_by_default: bool = True):
    """
    Decorator to cache API responses

    Args:
        client_name: Name of the API client
        ttl: Time-to-live in seconds (uses client default if None)
        enabled_by_default: Whether caching is enabled by default
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Check if caching is enabled (default True, can be overridden per call)
            use_cache = kwargs.pop('use_cache', enabled_by_default)

            if not use_cache:
                # Skip cache, make direct API call
                return func(*args, **kwargs)

            # Generate cache key (exclude 'self' from args)
            cache_args = args[1:] if args else ()
            cache_key = _cache_manager._generate_cache_key(
                client_name, func.__name__, cache_args, kwargs
            )

            # Try to get from cache
            cached_data = _cache_manager.get(cache_key, client_name)
            if cached_data is not None:
                return cached_data

            # Cache miss - make API call
            result = func(*args, **kwargs)

            # Cache the result
            _cache_manager.set(cache_key, client_name, result, ttl)

            return result

        return wrapper
    return decorator


def get_cache_manager() -> CacheManager:
    """Get the global cache manager instance"""
    return _cache_manager


if __name__ == "__main__":
    # Test the cache manager
    print("Cache Manager Test")
    print("=" * 50)

    cache = get_cache_manager()

    # Test caching
    print("\n1. Testing cache operations...")
    test_key = cache._generate_cache_key("Test Client", "test_method", ("arg1",), {})

    # Set cache
    cache.set(test_key, "Test Client", {"test": "data"}, ttl=60)
    print("   Cached test data")

    # Get cache
    result = cache.get(test_key, "Test Client")
    print(f"   Retrieved: {result}")

    # Stats
    stats = cache.get_stats()
    print(f"\n2. Cache stats: {stats}")

    # Cache info
    info = cache.get_cache_info()
    print(f"\n3. Cache info:")
    print(f"   Total entries: {info['total_entries']}")
    print(f"   Total size: {info['total_size_kb']} KB")
    print(f"   Entries by client: {info['entries_by_client']}")

    print("\n" + "=" * 50)
    print("Cache Manager: READY")
