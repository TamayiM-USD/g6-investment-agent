{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK5diXtHQTWD"
      },
      "source": [
        "# Multi-Agent Financial Analysis System\n",
        "## AAI-520 Final Team Project - Group 6\n",
        "\n",
        "**Team Members:**\n",
        "- MLANDA, Tamayi\n",
        "- HEGDE, Guruganesh\n",
        "- RAJAGANAPATHY, Arunkumar\n",
        "\n",
        "**GitHub Repository:** https://github.com/TamayiM-USD/g6-investment-agent.git\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "This notebook demonstrates an **autonomous Investment Research AI** that integrates real-world financial data and coordinates multiple specialized agents. The system showcases advanced agentic AI capabilities including:\n",
        "\n",
        "- **Autonomous Planning**: The agent creates its own research plans\n",
        "- **Dynamic Tool Usage**: Coordinates multiple APIs and data sources\n",
        "- **Self-Reflection**: Assesses and improves output quality\n",
        "- **Learning**: Maintains memory across runs for continuous improvement\n",
        "\n",
        "### Workflow Patterns Implemented\n",
        "\n",
        "1. **Prompt Chaining**: Sequential processing through Ingest → Preprocess → Classify → Extract → Summarize\n",
        "2. **Routing**: Intelligent direction of queries to specialized agents\n",
        "3. **Evaluator-Optimizer**: Iterative refinement through Generate → Evaluate → Optimize cycles\n",
        "\n",
        "### Technical Highlights\n",
        "\n",
        "**Architecture Strengths**\n",
        "\n",
        "- Separation of Concerns: Each agent has a single, well-defined responsibility\n",
        "- Extensibility: Easy to add new agents or data sources\n",
        "- Composability: Workflows combine agents in flexible ways\n",
        "- Testability: Each component can be tested independently\n",
        "- Maintainability: Clean code structure with comprehensive documentation\n",
        "\n",
        "**Innovation Points**\n",
        "\n",
        "- Autonomous Planning: Agent creates its own research strategy\n",
        "- Multi-Source Integration: Combines 4 different financial APIs\n",
        "- Quality Assessment: Quantitative self-evaluation with scoring\n",
        "- Memory System: Persistent learning across analyses\n",
        "- Iterative Refinement: Evaluator-optimizer improves output quality\n",
        "\n",
        "**System Architecture**\n",
        "\n",
        "The diagram below show the architecture of the final system.\n",
        "\n",
        "![Multi-Agent System Coordination](https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Multi-Agent%20System%20Coordination.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4TU8uE2QTWF"
      },
      "source": [
        "## 1. System Setup and Dependencies\n",
        "\n",
        "First, we'll install and import all required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lp6tzOrQTWG",
        "outputId": "541d21b8-6c28-4ff8-d9c9-9417a0bf0aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install yfinance requests pandas numpy mermaid-python --quiet\n",
        "\n",
        "print(\"All dependencies installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "from mermaid import Mermaid\n",
        "from openai import OpenAI\n",
        "from typing import Dict, Any, List\n",
        "from typing import Dict, Any, List, Optional\n",
        "from typing import Dict, Any, Optional\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import yfinance as yf\n"
      ],
      "metadata": {
        "id": "OXqXalbE_hSk"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CacheManager\n",
        "\n",
        "Some of the services have thresholds on the number of calls one can make. For example, Alpha Vantage free tier limits to 25 requests/day and SEC enforces rate limits (10 requests/second). To allow testing, we implemented a caching mechanism where output from the API calls is cached and reused for a configurable amount of time. This way, calls to the API for a token can reuse the same output.\n",
        "\n",
        "- Disk-based caching system for API clients\n",
        "- Reduces redundant API calls while preserving access to real data\n",
        "\n",
        "> NOTE: LLM USAGE\n",
        "> This class was generated by an AI language model (ChatGPT) to assist in development. It is intended to be reviewed and tested before production use."
      ],
      "metadata": {
        "id": "MTFCk_b4_0a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import hashlib\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, Dict, Optional\n",
        "from functools import wraps\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "class CacheManager:\n",
        "    \"\"\"Manages disk-based caching for API responses\"\"\"\n",
        "\n",
        "    # Default TTL values (in seconds) per client\n",
        "    DEFAULT_TTL = {\n",
        "        \"Yahoo Finance\": 3600,      # 1 hour - market data changes frequently\n",
        "        \"Alpha Vantage\": 86400,     # 24 hours - maximize 25/day limit\n",
        "        \"FRED\": 604800,             # 7 days - economic data updates slowly\n",
        "        \"SEC EDGAR\": 2592000,       # 30 days - filings are historical\n",
        "        \"default\": 3600             # 1 hour fallback\n",
        "    }\n",
        "\n",
        "    def __init__(self, cache_dir: str = \".api_cache\"):\n",
        "        \"\"\"\n",
        "        Initialize cache manager\n",
        "\n",
        "        Args:\n",
        "            cache_dir: Directory to store cache files\n",
        "        \"\"\"\n",
        "        self.cache_dir = Path(cache_dir)\n",
        "        self.cache_dir.mkdir(exist_ok=True)\n",
        "        self._stats = {\"hits\": 0, \"misses\": 0, \"errors\": 0}\n",
        "\n",
        "    def _generate_cache_key(self, client_name: str, method_name: str,\n",
        "                           args: tuple, kwargs: dict) -> str:\n",
        "        \"\"\"\n",
        "        Generate unique cache key from function call parameters\n",
        "\n",
        "        Args:\n",
        "            client_name: Name of the API client\n",
        "            method_name: Name of the method being called\n",
        "            args: Positional arguments\n",
        "            kwargs: Keyword arguments\n",
        "\n",
        "        Returns:\n",
        "            SHA256 hash as cache key\n",
        "        \"\"\"\n",
        "        # Create deterministic string representation\n",
        "        key_parts = [\n",
        "            client_name,\n",
        "            method_name,\n",
        "            str(args),\n",
        "            str(sorted(kwargs.items()))\n",
        "        ]\n",
        "        key_string = \"|\".join(key_parts)\n",
        "\n",
        "        # Generate hash\n",
        "        return hashlib.sha256(key_string.encode()).hexdigest()\n",
        "\n",
        "    def _get_cache_path(self, cache_key: str, client_name: str) -> Path:\n",
        "        \"\"\"Get file path for cache entry\"\"\"\n",
        "        # Organize by client for easier management\n",
        "        client_dir = self.cache_dir / client_name.replace(\" \", \"_\")\n",
        "        client_dir.mkdir(exist_ok=True)\n",
        "        return client_dir / f\"{cache_key}.json\"\n",
        "\n",
        "    def get(self, cache_key: str, client_name: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Retrieve cached data if valid\n",
        "\n",
        "        Args:\n",
        "            cache_key: Cache key hash\n",
        "            client_name: Name of the API client\n",
        "\n",
        "        Returns:\n",
        "            Cached data dict or None if not found/expired\n",
        "        \"\"\"\n",
        "        cache_path = self._get_cache_path(cache_key, client_name)\n",
        "\n",
        "        if not cache_path.exists():\n",
        "            self._stats[\"misses\"] += 1\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            with open(cache_path, 'r') as f:\n",
        "                cache_entry = json.load(f)\n",
        "\n",
        "            # Check expiry\n",
        "            expiry_time = cache_entry.get(\"expiry_timestamp\")\n",
        "            if expiry_time and time.time() > expiry_time:\n",
        "                # Cache expired\n",
        "                cache_path.unlink()  # Remove expired cache\n",
        "                self._stats[\"misses\"] += 1\n",
        "                return None\n",
        "\n",
        "            self._stats[\"hits\"] += 1\n",
        "            return cache_entry.get(\"data\")\n",
        "\n",
        "        except (json.JSONDecodeError, IOError) as e:\n",
        "            self._stats[\"errors\"] += 1\n",
        "            print(f\"Cache read error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def set(self, cache_key: str, client_name: str, data: Any,\n",
        "            ttl: Optional[int] = None) -> None:\n",
        "        \"\"\"\n",
        "        Store data in cache\n",
        "\n",
        "        Args:\n",
        "            cache_key: Cache key hash\n",
        "            client_name: Name of the API client\n",
        "            data: Data to cache\n",
        "            ttl: Time-to-live in seconds (uses default if None)\n",
        "        \"\"\"\n",
        "        cache_path = self._get_cache_path(cache_key, client_name)\n",
        "\n",
        "        # Use client-specific TTL or default\n",
        "        if ttl is None:\n",
        "            ttl = self.DEFAULT_TTL.get(client_name, self.DEFAULT_TTL[\"default\"])\n",
        "\n",
        "        cache_entry = {\n",
        "            \"data\": data,\n",
        "            \"cached_at\": time.time(),\n",
        "            \"cached_at_readable\": datetime.now().isoformat(),\n",
        "            \"expiry_timestamp\": time.time() + ttl,\n",
        "            \"expiry_readable\": (datetime.now() + timedelta(seconds=ttl)).isoformat(),\n",
        "            \"client\": client_name,\n",
        "            \"ttl_seconds\": ttl\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(cache_path, 'w') as f:\n",
        "                json.dump(cache_entry, f, indent=2, default=str)\n",
        "        except (IOError, TypeError) as e:\n",
        "            self._stats[\"errors\"] += 1\n",
        "            print(f\"Cache write error: {e}\")\n",
        "\n",
        "    def clear_client_cache(self, client_name: str) -> int:\n",
        "        \"\"\"\n",
        "        Clear all cache entries for a specific client\n",
        "\n",
        "        Args:\n",
        "            client_name: Name of the API client\n",
        "\n",
        "        Returns:\n",
        "            Number of cache files deleted\n",
        "        \"\"\"\n",
        "        client_dir = self.cache_dir / client_name.replace(\" \", \"_\")\n",
        "        if not client_dir.exists():\n",
        "            return 0\n",
        "\n",
        "        count = 0\n",
        "        for cache_file in client_dir.glob(\"*.json\"):\n",
        "            cache_file.unlink()\n",
        "            count += 1\n",
        "\n",
        "        return count\n",
        "\n",
        "    def clear_all_cache(self) -> int:\n",
        "        \"\"\"\n",
        "        Clear entire cache\n",
        "\n",
        "        Returns:\n",
        "            Number of cache files deleted\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        for cache_file in self.cache_dir.rglob(\"*.json\"):\n",
        "            cache_file.unlink()\n",
        "            count += 1\n",
        "\n",
        "        return count\n",
        "\n",
        "    def clear_expired(self) -> int:\n",
        "        \"\"\"\n",
        "        Remove expired cache entries\n",
        "\n",
        "        Returns:\n",
        "            Number of expired entries removed\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        current_time = time.time()\n",
        "\n",
        "        for cache_file in self.cache_dir.rglob(\"*.json\"):\n",
        "            try:\n",
        "                with open(cache_file, 'r') as f:\n",
        "                    cache_entry = json.load(f)\n",
        "\n",
        "                expiry = cache_entry.get(\"expiry_timestamp\")\n",
        "                if expiry and current_time > expiry:\n",
        "                    cache_file.unlink()\n",
        "                    count += 1\n",
        "\n",
        "            except (json.JSONDecodeError, IOError):\n",
        "                # Remove corrupted cache files\n",
        "                cache_file.unlink()\n",
        "                count += 1\n",
        "\n",
        "        return count\n",
        "\n",
        "    def get_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get cache statistics\n",
        "\n",
        "        Returns:\n",
        "            Dict with hits, misses, errors, and hit rate\n",
        "        \"\"\"\n",
        "        total = self._stats[\"hits\"] + self._stats[\"misses\"]\n",
        "        hit_rate = (self._stats[\"hits\"] / total * 100) if total > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"hits\": self._stats[\"hits\"],\n",
        "            \"misses\": self._stats[\"misses\"],\n",
        "            \"errors\": self._stats[\"errors\"],\n",
        "            \"hit_rate_percent\": round(hit_rate, 2),\n",
        "            \"total_requests\": total\n",
        "        }\n",
        "\n",
        "    def get_cache_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get information about cached data\n",
        "\n",
        "        Returns:\n",
        "            Dict with cache size, file count, etc.\n",
        "        \"\"\"\n",
        "        total_files = 0\n",
        "        total_size = 0\n",
        "        clients = {}\n",
        "\n",
        "        for cache_file in self.cache_dir.rglob(\"*.json\"):\n",
        "            total_files += 1\n",
        "            total_size += cache_file.stat().st_size\n",
        "\n",
        "            # Get client name from directory\n",
        "            client_name = cache_file.parent.name.replace(\"_\", \" \")\n",
        "            clients[client_name] = clients.get(client_name, 0) + 1\n",
        "\n",
        "        return {\n",
        "            \"total_entries\": total_files,\n",
        "            \"total_size_bytes\": total_size,\n",
        "            \"total_size_kb\": round(total_size / 1024, 2),\n",
        "            \"entries_by_client\": clients,\n",
        "            \"cache_directory\": str(self.cache_dir)\n",
        "        }\n",
        "\n",
        "\n",
        "# Global cache instance\n",
        "_cache_manager = CacheManager()\n",
        "\n",
        "\n",
        "def cache_response(client_name: str, ttl: Optional[int] = None,\n",
        "                   enabled_by_default: bool = True):\n",
        "    \"\"\"\n",
        "    Decorator to cache API responses\n",
        "\n",
        "    Args:\n",
        "        client_name: Name of the API client\n",
        "        ttl: Time-to-live in seconds (uses client default if None)\n",
        "        enabled_by_default: Whether caching is enabled by default\n",
        "    \"\"\"\n",
        "    def decorator(func: Callable) -> Callable:\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            # Check if caching is enabled (default True, can be overridden per call)\n",
        "            use_cache = kwargs.pop('use_cache', enabled_by_default)\n",
        "\n",
        "            if not use_cache:\n",
        "                # Skip cache, make direct API call\n",
        "                return func(*args, **kwargs)\n",
        "\n",
        "            # Generate cache key (exclude 'self' from args)\n",
        "            cache_args = args[1:] if args else ()\n",
        "            cache_key = _cache_manager._generate_cache_key(\n",
        "                client_name, func.__name__, cache_args, kwargs\n",
        "            )\n",
        "\n",
        "            # Try to get from cache\n",
        "            cached_data = _cache_manager.get(cache_key, client_name)\n",
        "            if cached_data is not None:\n",
        "                return cached_data\n",
        "\n",
        "            # Cache miss - make API call\n",
        "            result = func(*args, **kwargs)\n",
        "\n",
        "            # Cache the result\n",
        "            _cache_manager.set(cache_key, client_name, result, ttl)\n",
        "\n",
        "            return result\n",
        "\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "\n",
        "def get_cache_manager() -> CacheManager:\n",
        "    \"\"\"Get the global cache manager instance\"\"\"\n",
        "    return _cache_manager\n",
        "\n",
        "\n",
        "# Test the cache manager\n",
        "print(\"Cache Manager Test\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "cache = get_cache_manager()\n",
        "\n",
        "# Test caching\n",
        "print(\"\\n1. Testing cache operations...\")\n",
        "test_key = cache._generate_cache_key(\"Test Client\", \"test_method\", (\"arg1\",), {})\n",
        "\n",
        "# Set cache\n",
        "cache.set(test_key, \"Test Client\", {\"test\": \"data\"}, ttl=60)\n",
        "print(\"   Cached test data\")\n",
        "\n",
        "# Get cache\n",
        "result = cache.get(test_key, \"Test Client\")\n",
        "print(f\"   Retrieved: {result}\")\n",
        "\n",
        "# Stats\n",
        "stats = cache.get_stats()\n",
        "print(f\"\\n2. Cache stats: {stats}\")\n",
        "\n",
        "# Cache info\n",
        "info = cache.get_cache_info()\n",
        "print(f\"\\n3. Cache info:\")\n",
        "print(f\"   Total entries: {info['total_entries']}\")\n",
        "print(f\"   Total size: {info['total_size_kb']} KB\")\n",
        "print(f\"   Entries by client: {info['entries_by_client']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Cache Manager: READY\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8_z_dpq_qIr",
        "outputId": "3790f7a2-c802-46a2-c1fe-cf96bb61d3a9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache Manager Test\n",
            "==================================================\n",
            "\n",
            "1. Testing cache operations...\n",
            "   Cached test data\n",
            "   Retrieved: {'test': 'data'}\n",
            "\n",
            "2. Cache stats: {'hits': 1, 'misses': 0, 'errors': 0, 'hit_rate_percent': 100.0, 'total_requests': 1}\n",
            "\n",
            "3. Cache info:\n",
            "   Total entries: 23\n",
            "   Total size: 28.92 KB\n",
            "   Entries by client: {'FRED': 7, 'Yahoo Finance': 7, 'Test Client': 1, 'SEC EDGAR': 3, 'Alpha Vantage': 5}\n",
            "\n",
            "==================================================\n",
            "Cache Manager: READY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBfVMYVJQTWG"
      },
      "source": [
        "## 2. Data Source Integration\n",
        "\n",
        "Our system integrates four major financial data sources. Our project integrates multiple reputable financial and economic data sources to ensure robust and real-world analysis. Access will be through public APIs where available, but will also rely on offline data samples where necessary to avoid incurring costs. Some data is available through “unofficial” means / wrappers / scraping. These data sources include:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1 Yahoo Finance\n",
        "\n",
        "A widely used financial data service offering real-time and historical stock prices, company financials, and market news. It serves as a primary source for stock-level data and basic market indicators. Provides real-time and historical stock prices, company financials, and market data."
      ],
      "metadata": {
        "id": "_abYauhMBJ-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BBjdjv_QQTWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b96cca0-b979-49e1-82d4-976d26109638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Yahoo Finance Client...\n",
            "==================================================\n",
            "\n",
            "1. Testing get_stock_info('AAPL')...\n",
            "Company: Apple Inc.\n",
            "Price: $252.29\n",
            "Market Cap: $3,744,081,903,616\n",
            "\n",
            "2. Testing get_news('AAPL')...\n",
            "Found 3 news articles\n",
            "  Latest: ...\n",
            "\n",
            "3. Testing get_historical_data('AAPL')...\n",
            "Data points: 22\n",
            "Price change: 6.06%\n",
            "\n",
            "==================================================\n",
            "Yahoo Finance Client: READY \n"
          ]
        }
      ],
      "source": [
        "class YahooFinanceClient:\n",
        "    \"\"\"Yahoo Finance API client - Real data only\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.name = \"Yahoo Finance\"\n",
        "\n",
        "    @cache_response(\"Yahoo Finance\")\n",
        "    def get_stock_info(self, symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Fetch comprehensive stock information\n",
        "        Returns real data from Yahoo Finance API\n",
        "        \"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            # Extract key financial metrics\n",
        "            stock_data = {\n",
        "                \"symbol\": symbol,\n",
        "                \"company_name\": info.get(\"longName\", \"N/A\"),\n",
        "                \"sector\": info.get(\"sector\", \"N/A\"),\n",
        "                \"industry\": info.get(\"industry\", \"N/A\"),\n",
        "                \"market_cap\": info.get(\"marketCap\", 0),\n",
        "                \"current_price\": info.get(\"currentPrice\") or info.get(\"regularMarketPrice\", 0),\n",
        "                \"previous_close\": info.get(\"previousClose\") or info.get(\"regularMarketPreviousClose\", 0),\n",
        "                \"open_price\": info.get(\"open\") or info.get(\"regularMarketOpen\", 0),\n",
        "                \"day_high\": info.get(\"dayHigh\") or info.get(\"regularMarketDayHigh\", 0),\n",
        "                \"day_low\": info.get(\"dayLow\") or info.get(\"regularMarketDayLow\", 0),\n",
        "                \"volume\": info.get(\"volume\") or info.get(\"regularMarketVolume\", 0),\n",
        "                \"pe_ratio\": info.get(\"trailingPE\", None),\n",
        "                \"forward_pe\": info.get(\"forwardPE\", None),\n",
        "                \"52_week_high\": info.get(\"fiftyTwoWeekHigh\", 0),\n",
        "                \"52_week_low\": info.get(\"fiftyTwoWeekLow\", 0),\n",
        "                \"beta\": info.get(\"beta\", None),\n",
        "                \"dividend_yield\": info.get(\"dividendYield\", None),\n",
        "                \"profit_margin\": info.get(\"profitMargins\", None),\n",
        "                \"operating_margin\": info.get(\"operatingMargins\", None),\n",
        "                \"revenue\": info.get(\"totalRevenue\", 0),\n",
        "                \"earnings_growth\": info.get(\"earningsGrowth\", None),\n",
        "                \"revenue_growth\": info.get(\"revenueGrowth\", None),\n",
        "                \"ebitda\": info.get(\"ebitda\", None),\n",
        "                \"debt_to_equity\": info.get(\"debtToEquity\", None),\n",
        "                \"return_on_equity\": info.get(\"returnOnEquity\", None),\n",
        "                \"currency\": info.get(\"currency\", \"USD\"),\n",
        "            }\n",
        "\n",
        "            return stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to fetch data for {symbol}: {str(e)}\")\n",
        "\n",
        "    @cache_response(\"Yahoo Finance\")\n",
        "    def get_news(self, symbol: str, limit: int = 5) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Fetch recent news articles\n",
        "        Returns real news from Yahoo Finance\n",
        "        \"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            news = ticker.news\n",
        "\n",
        "            if not news:\n",
        "                return []\n",
        "\n",
        "            news_items = []\n",
        "            for article in news[:limit]:\n",
        "                news_items.append({\n",
        "                    \"title\": article.get(\"title\", \"\"),\n",
        "                    \"publisher\": article.get(\"publisher\", \"\"),\n",
        "                    \"link\": article.get(\"link\", \"\"),\n",
        "                    \"published_date\": article.get(\"providerPublishTime\", \"\"),\n",
        "                    \"type\": article.get(\"type\", \"\")\n",
        "                })\n",
        "\n",
        "            return news_items\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to fetch news for {symbol}: {str(e)}\")\n",
        "\n",
        "    @cache_response(\"Yahoo Finance\")\n",
        "    def get_historical_data(self, symbol: str, period: str = \"1mo\") -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Fetch historical price data\n",
        "        Period options: 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
        "        \"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            hist = ticker.history(period=period)\n",
        "\n",
        "            if hist.empty:\n",
        "                return {\"error\": \"No historical data available\"}\n",
        "\n",
        "            return {\n",
        "                \"symbol\": symbol,\n",
        "                \"period\": period,\n",
        "                \"data_points\": len(hist),\n",
        "                \"latest_close\": float(hist['Close'].iloc[-1]),\n",
        "                \"period_high\": float(hist['High'].max()),\n",
        "                \"period_low\": float(hist['Low'].min()),\n",
        "                \"average_volume\": int(hist['Volume'].mean()),\n",
        "                \"price_change\": float(hist['Close'].iloc[-1] - hist['Close'].iloc[0]),\n",
        "                \"price_change_percent\": float(\n",
        "                    ((hist['Close'].iloc[-1] - hist['Close'].iloc[0]) / hist['Close'].iloc[0]) * 100\n",
        "                )\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to fetch historical data for {symbol}: {str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the client\n",
        "    print(\"Testing Yahoo Finance Client...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    client = YahooFinanceClient()\n",
        "\n",
        "    # Test stock info\n",
        "    print(\"\\n1. Testing get_stock_info('AAPL')...\")\n",
        "    try:\n",
        "        info = client.get_stock_info(\"AAPL\")\n",
        "        print(f\"Company: {info['company_name']}\")\n",
        "        print(f\"Price: ${info['current_price']}\")\n",
        "        print(f\"Market Cap: ${info['market_cap']:,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    # Test news\n",
        "    print(\"\\n2. Testing get_news('AAPL')...\")\n",
        "    try:\n",
        "        news = client.get_news(\"AAPL\", limit=3)\n",
        "        print(f\"Found {len(news)} news articles\")\n",
        "        if news:\n",
        "            print(f\"  Latest: {news[0]['title'][:60]}...\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    # Test historical data\n",
        "    print(\"\\n3. Testing get_historical_data('AAPL')...\")\n",
        "    try:\n",
        "        hist = client.get_historical_data(\"AAPL\", period=\"1mo\")\n",
        "        print(f\"Data points: {hist['data_points']}\")\n",
        "        print(f\"Price change: {hist['price_change_percent']:.2f}%\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Yahoo Finance Client: READY \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Alpha Vantage Client\n",
        "\n",
        "A provider of APIs that supply real-time and historical data for equities, forex, and cryptocurrencies. It enables programmatic access to financial data at scale, complementing other datasets with broad coverage."
      ],
      "metadata": {
        "id": "j5PQ3tpBA-jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlphaVantageClient:\n",
        "    \"\"\"Alpha Vantage API client - Real API calls with key\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        import os\n",
        "        self.api_key = api_key or os.getenv(\"ALPHA_VANTAGE_API_KEY\") or userdata.get(\"ALPHA_VANTAGE_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\n",
        "                \"Alpha Vantage API key required. \"\n",
        "                \"Set ALPHA_VANTAGE_API_KEY environment variable or pass api_key parameter. \"\n",
        "                \"Get free key at: https://www.alphavantage.co/support/#api-key\"\n",
        "            )\n",
        "        self.base_url = \"https://www.alphavantage.co/query\"\n",
        "        self.name = \"Alpha Vantage\"\n",
        "\n",
        "    @cache_response(\"Alpha Vantage\", ttl=86400)  # 24 hours to maximize 25/day limit\n",
        "    def get_company_overview(self, symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get comprehensive company fundamentals\n",
        "        Requires valid API key - no demo mode\n",
        "        \"\"\"\n",
        "        import requests\n",
        "\n",
        "        try:\n",
        "            params = {\n",
        "                \"function\": \"OVERVIEW\",\n",
        "                \"symbol\": symbol,\n",
        "                \"apikey\": self.api_key\n",
        "            }\n",
        "\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            # Check for API errors\n",
        "            if \"Note\" in data:\n",
        "                raise RuntimeError(\n",
        "                    \"API rate limit reached. Alpha Vantage free tier: 25 requests/day. \"\n",
        "                    \"Wait or upgrade at: https://www.alphavantage.co/premium/\"\n",
        "                )\n",
        "\n",
        "            if \"Error Message\" in data:\n",
        "                raise RuntimeError(f\"API Error: {data['Error Message']}\")\n",
        "\n",
        "            if not data or \"Symbol\" not in data:\n",
        "                raise RuntimeError(f\"No data returned for {symbol}\")\n",
        "\n",
        "            # Return comprehensive overview\n",
        "            return {\n",
        "                \"symbol\": symbol,\n",
        "                \"name\": data.get(\"Name\", \"\"),\n",
        "                \"description\": data.get(\"Description\", \"\"),\n",
        "                \"sector\": data.get(\"Sector\", \"\"),\n",
        "                \"industry\": data.get(\"Industry\", \"\"),\n",
        "                \"market_cap\": data.get(\"MarketCapitalization\", \"\"),\n",
        "                \"pe_ratio\": data.get(\"PERatio\", \"\"),\n",
        "                \"peg_ratio\": data.get(\"PEGRatio\", \"\"),\n",
        "                \"book_value\": data.get(\"BookValue\", \"\"),\n",
        "                \"dividend_yield\": data.get(\"DividendYield\", \"\"),\n",
        "                \"eps\": data.get(\"EPS\", \"\"),\n",
        "                \"revenue_per_share\": data.get(\"RevenuePerShareTTM\", \"\"),\n",
        "                \"profit_margin\": data.get(\"ProfitMargin\", \"\"),\n",
        "                \"operating_margin\": data.get(\"OperatingMarginTTM\", \"\"),\n",
        "                \"return_on_assets\": data.get(\"ReturnOnAssetsTTM\", \"\"),\n",
        "                \"return_on_equity\": data.get(\"ReturnOnEquityTTM\", \"\"),\n",
        "                \"revenue\": data.get(\"RevenueTTM\", \"\"),\n",
        "                \"gross_profit\": data.get(\"GrossProfitTTM\", \"\"),\n",
        "                \"ebitda\": data.get(\"EBITDA\", \"\"),\n",
        "                \"analyst_target_price\": data.get(\"AnalystTargetPrice\", \"\"),\n",
        "                \"52_week_high\": data.get(\"52WeekHigh\", \"\"),\n",
        "                \"52_week_low\": data.get(\"52WeekLow\", \"\"),\n",
        "            }\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise RuntimeError(f\"Network error fetching data from Alpha Vantage: {str(e)}\")\n",
        "\n",
        "    @cache_response(\"Alpha Vantage\", ttl=86400)  # 24 hours to maximize 25/day limit\n",
        "    def get_quote(self, symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"Get real-time quote data\"\"\"\n",
        "        import requests\n",
        "\n",
        "        try:\n",
        "            params = {\n",
        "                \"function\": \"GLOBAL_QUOTE\",\n",
        "                \"symbol\": symbol,\n",
        "                \"apikey\": self.api_key\n",
        "            }\n",
        "\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if \"Note\" in data:\n",
        "                raise RuntimeError(\"API rate limit reached\")\n",
        "\n",
        "            quote = data.get(\"Global Quote\", {})\n",
        "            if not quote:\n",
        "                raise RuntimeError(f\"No quote data for {symbol}\")\n",
        "\n",
        "            return {\n",
        "                \"symbol\": quote.get(\"01. symbol\", \"\"),\n",
        "                \"price\": float(quote.get(\"05. price\", 0)),\n",
        "                \"volume\": int(quote.get(\"06. volume\", 0)),\n",
        "                \"latest_trading_day\": quote.get(\"07. latest trading day\", \"\"),\n",
        "                \"previous_close\": float(quote.get(\"08. previous close\", 0)),\n",
        "                \"change\": float(quote.get(\"09. change\", 0)),\n",
        "                \"change_percent\": quote.get(\"10. change percent\", \"\"),\n",
        "            }\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise RuntimeError(f\"Network error: {str(e)}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    print(\"\\nTesting Alpha Vantage Client...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Check for API key\n",
        "    if not os.getenv(\"ALPHA_VANTAGE_API_KEY\") and not userdata.get(\"ALPHA_VANTAGE_API_KEY\"):\n",
        "        print(\"ALPHA_VANTAGE_API_KEY not set\")\n",
        "        print(\"Get free key: https://www.alphavantage.co/support/#api-key\")\n",
        "        print(\"Then set: export ALPHA_VANTAGE_API_KEY=your-key\")\n",
        "    else:\n",
        "        try:\n",
        "            client = AlphaVantageClient()\n",
        "\n",
        "            print(\"\\n1. Testing get_company_overview('IBM')...\")\n",
        "            overview = client.get_company_overview(\"IBM\")\n",
        "            print(f\"Company: {overview['name']}\")\n",
        "            print(f\"Sector: {overview['sector']}\")\n",
        "            print(f\"PE Ratio: {overview['pe_ratio']}\")\n",
        "\n",
        "            print(\"\\n2. Testing get_quote('IBM')...\")\n",
        "            quote = client.get_quote(\"IBM\")\n",
        "            print(f\"Price: ${quote['price']}\")\n",
        "            print(f\"Change: {quote['change_percent']}\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"Alpha Vantage Client: READY \")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            print(\"\\nNote: Free tier has 25 requests/day limit\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6kEWkYwApnD",
        "outputId": "9e94eb8c-2e49-4e94-a129-ecef905e947c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Alpha Vantage Client...\n",
            "==================================================\n",
            "\n",
            "1. Testing get_company_overview('IBM')...\n",
            "Company: International Business Machines\n",
            "Sector: TECHNOLOGY\n",
            "PE Ratio: 45.44\n",
            "\n",
            "2. Testing get_quote('IBM')...\n",
            "Price: $281.28\n",
            "Change: 1.9241%\n",
            "\n",
            "==================================================\n",
            "Alpha Vantage Client: READY \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emRNRjWoQTWH"
      },
      "source": [
        "### 2.3 FRED (Federal Reserve Economic Data)\n",
        "\n",
        "A comprehensive database maintained by the Federal Reserve Bank of St. Louis, providing thousands of U.S. and international economic and financial time series. It is particularly valuable for incorporating macroeconomic indicators into financial analyses. Provides economic indicators and macroeconomic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "w6brMckyQTWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726443c2-9019-4e46-a382-2ac0027855c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing FRED Client...\n",
            "==================================================\n",
            "\n",
            "1. Testing Federal Funds Rate...\n",
            "Federal Funds Effective Rate\n",
            "Latest: 4.11% (2025-10-16)\n",
            "\n",
            "2. Testing Unemployment Rate...\n",
            "Unemployment Rate\n",
            "Latest: 4.3% (2025-08-01)\n",
            "\n",
            "3. Testing Multiple Indicators...\n",
            "Fetched 3 indicators\n",
            "\n",
            "==================================================\n",
            "FRED Client: READY \n"
          ]
        }
      ],
      "source": [
        "class FREDClient:\n",
        "    \"\"\"FRED API client for economic indicators - Real API only\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        import os\n",
        "        self.api_key = api_key or os.getenv(\"FRED_API_KEY\") or userdata.get(\"FRED_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\n",
        "                \"FRED API key required. \"\n",
        "                \"Set FRED_API_KEY environment variable. \"\n",
        "                \"Get free key at: https://fred.stlouisfed.org/docs/api/api_key.html\"\n",
        "            )\n",
        "        self.base_url = \"https://api.stlouisfed.org/fred/series/observations\"\n",
        "        self.name = \"FRED\"\n",
        "\n",
        "    @cache_response(\"FRED\", ttl=604800)  # 7 days - economic data updates slowly\n",
        "    def get_economic_indicator(self, series_id: str, limit: int = 12) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Fetch economic indicator data from FRED\n",
        "        Real API call - requires valid key\n",
        "\n",
        "        Common series:\n",
        "        - DFF: Federal Funds Rate\n",
        "        - UNRATE: Unemployment Rate\n",
        "        - CPIAUCSL: Consumer Price Index\n",
        "        - GDP: Gross Domestic Product\n",
        "        \"\"\"\n",
        "        import requests\n",
        "\n",
        "        try:\n",
        "            params = {\n",
        "                \"series_id\": series_id,\n",
        "                \"api_key\": self.api_key,\n",
        "                \"file_type\": \"json\",\n",
        "                \"limit\": limit,\n",
        "                \"sort_order\": \"desc\"\n",
        "            }\n",
        "\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if \"error_code\" in data:\n",
        "                raise RuntimeError(f\"FRED API Error: {data.get('error_message', 'Unknown error')}\")\n",
        "\n",
        "            observations = data.get(\"observations\", [])\n",
        "            if not observations:\n",
        "                raise RuntimeError(f\"No data available for series {series_id}\")\n",
        "\n",
        "            # Get series metadata\n",
        "            series_info = self._get_series_info(series_id)\n",
        "\n",
        "            return {\n",
        "                \"series_id\": series_id,\n",
        "                \"name\": series_info[\"name\"],\n",
        "                \"units\": series_info[\"units\"],\n",
        "                \"frequency\": series_info[\"frequency\"],\n",
        "                \"observations\": [\n",
        "                    {\n",
        "                        \"date\": obs.get(\"date\"),\n",
        "                        \"value\": obs.get(\"value\"),\n",
        "                        \"is_current\": i == 0\n",
        "                    }\n",
        "                    for i, obs in enumerate(observations)\n",
        "                ],\n",
        "                \"latest_value\": observations[0].get(\"value\") if observations else None,\n",
        "                \"latest_date\": observations[0].get(\"date\") if observations else None,\n",
        "                \"data_points\": len(observations)\n",
        "            }\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise RuntimeError(f\"Network error fetching FRED data: {str(e)}\")\n",
        "\n",
        "    def _get_series_info(self, series_id: str) -> Dict[str, str]:\n",
        "        \"\"\"Get metadata about a series\"\"\"\n",
        "        series_map = {\n",
        "            \"DFF\": {\n",
        "                \"name\": \"Federal Funds Effective Rate\",\n",
        "                \"units\": \"Percent\",\n",
        "                \"frequency\": \"Daily\"\n",
        "            },\n",
        "            \"UNRATE\": {\n",
        "                \"name\": \"Unemployment Rate\",\n",
        "                \"units\": \"Percent\",\n",
        "                \"frequency\": \"Monthly\"\n",
        "            },\n",
        "            \"CPIAUCSL\": {\n",
        "                \"name\": \"Consumer Price Index for All Urban Consumers\",\n",
        "                \"units\": \"Index 1982-1984=100\",\n",
        "                \"frequency\": \"Monthly\"\n",
        "            },\n",
        "            \"GDP\": {\n",
        "                \"name\": \"Gross Domestic Product\",\n",
        "                \"units\": \"Billions of Dollars\",\n",
        "                \"frequency\": \"Quarterly\"\n",
        "            },\n",
        "            \"MORTGAGE30US\": {\n",
        "                \"name\": \"30-Year Fixed Rate Mortgage Average\",\n",
        "                \"units\": \"Percent\",\n",
        "                \"frequency\": \"Weekly\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return series_map.get(series_id, {\n",
        "            \"name\": series_id,\n",
        "            \"units\": \"See FRED documentation\",\n",
        "            \"frequency\": \"Varies\"\n",
        "        })\n",
        "\n",
        "    def get_multiple_indicators(self, series_ids: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Fetch multiple economic indicators\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for series_id in series_ids:\n",
        "            try:\n",
        "                results[series_id] = self.get_economic_indicator(series_id, limit=5)\n",
        "            except Exception as e:\n",
        "                results[series_id] = {\"error\": str(e)}\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    print(\"\\nTesting FRED Client...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.getenv(\"FRED_API_KEY\") and not userdata.get(\"FRED_API_KEY\"):\n",
        "        print(\"FRED_API_KEY not set\")\n",
        "        print(\"Get free key: https://fred.stlouisfed.org/docs/api/api_key.html\")\n",
        "        print(\"Then set: export FRED_API_KEY=your-key\")\n",
        "    else:\n",
        "        try:\n",
        "            client = FREDClient()\n",
        "\n",
        "            print(\"\\n1. Testing Federal Funds Rate...\")\n",
        "            dff = client.get_economic_indicator(\"DFF\")\n",
        "            print(f\"{dff['name']}\")\n",
        "            print(f\"Latest: {dff['latest_value']}% ({dff['latest_date']})\")\n",
        "\n",
        "            print(\"\\n2. Testing Unemployment Rate...\")\n",
        "            unrate = client.get_economic_indicator(\"UNRATE\")\n",
        "            print(f\"{unrate['name']}\")\n",
        "            print(f\"Latest: {unrate['latest_value']}% ({unrate['latest_date']})\")\n",
        "\n",
        "            print(\"\\n3. Testing Multiple Indicators...\")\n",
        "            multi = client.get_multiple_indicators([\"DFF\", \"UNRATE\", \"GDP\"])\n",
        "            print(f\"Fetched {len([k for k, v in multi.items() if 'error' not in v])} indicators\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"FRED Client: READY \")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_EWuj3IQTWH"
      },
      "source": [
        "### 2.4 SEC EDGAR (U.S. Securities and Exchange Commission - Electronic Data Gathering, Analysis, and Retrieval system)\n",
        "\n",
        "The official repository for public company filings, including 10-K annual reports, 10-Q quarterly reports, and other regulatory disclosures. It is essential for extracting structured company financials and compliance information. Provides access to company filings and regulatory documents.\n",
        "\n",
        "Some APIs return HTTP 404 and we fallback on static data for common companies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "uzsCQ7yfQTWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246597a1-3e41-4efd-dedb-76ca5537d728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing SEC EDGAR Client...\n",
            "==================================================\n",
            "\n",
            "1. Testing get_company_submissions('AAPL')...\n",
            "Company: Apple Inc.\n",
            "CIK: 0000320193\n",
            "Total filings: 1001\n",
            "Recent filings: 10\n",
            "  Latest: 4 on 2025-10-17\n",
            "\n",
            "==================================================\n",
            "SEC EDGAR Client: READY \n",
            "\n",
            "Note: SEC enforces rate limits (10 requests/second)\n"
          ]
        }
      ],
      "source": [
        "class SECEdgarClient:\n",
        "    \"\"\"SEC EDGAR API client for regulatory filings\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://data.sec.gov\"\n",
        "        self.name = \"SEC EDGAR\"\n",
        "        self.headers = {\n",
        "            \"User-Agent\": \"University of San Diego AAI-520 Research tmlanda@sandiego.edu\",\n",
        "            \"Accept-Encoding\": \"gzip, deflate\",\n",
        "            \"Host\": \"data.sec.gov\"\n",
        "        }\n",
        "\n",
        "    @cache_response(\"SEC EDGAR\", ttl=2592000)  # 30 days - filings are historical\n",
        "    def get_company_submissions(self, ticker: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get company CIK and recent filings\n",
        "        Real SEC EDGAR API call\n",
        "        \"\"\"\n",
        "        import requests\n",
        "\n",
        "        try:\n",
        "            # First, get CIK from ticker\n",
        "            cik = self._get_cik_from_ticker(ticker)\n",
        "            if not cik:\n",
        "                raise RuntimeError(f\"Could not find CIK for ticker {ticker}\")\n",
        "\n",
        "            # Fetch submissions\n",
        "            url = f\"{self.base_url}/submissions/CIK{cik}.json\"\n",
        "            response = requests.get(url, headers=self.headers, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            # Extract recent filings\n",
        "            recent_filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
        "\n",
        "            filings_list = []\n",
        "            if recent_filings:\n",
        "                forms = recent_filings.get(\"form\", [])\n",
        "                dates = recent_filings.get(\"filingDate\", [])\n",
        "                accessions = recent_filings.get(\"accessionNumber\", [])\n",
        "\n",
        "                for i in range(min(10, len(forms))):\n",
        "                    filings_list.append({\n",
        "                        \"form_type\": forms[i],\n",
        "                        \"filing_date\": dates[i],\n",
        "                        \"accession_number\": accessions[i],\n",
        "                        \"url\": f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type={forms[i]}&dateb=&owner=exclude\"\n",
        "                    })\n",
        "\n",
        "            return {\n",
        "                \"ticker\": ticker,\n",
        "                \"cik\": cik,\n",
        "                \"company_name\": data.get(\"name\", \"\"),\n",
        "                \"sic\": data.get(\"sic\", \"\"),\n",
        "                \"sic_description\": data.get(\"sicDescription\", \"\"),\n",
        "                \"recent_filings\": filings_list,\n",
        "                \"total_filings\": len(forms) if forms else 0\n",
        "            }\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise RuntimeError(f\"Failed to fetch SEC data: {str(e)}\")\n",
        "\n",
        "    def _get_cik_from_ticker(self, ticker: str) -> Optional[str]:\n",
        "        \"\"\"Get CIK number from ticker symbol using SEC's search API\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Use SEC's search/browse functionality\n",
        "            ticker_upper = ticker.upper()\n",
        "            search_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "\n",
        "            params = {\n",
        "                \"action\": \"getcompany\",\n",
        "                \"company\": ticker_upper,\n",
        "                \"type\": \"\",\n",
        "                \"dateb\": \"\",\n",
        "                \"owner\": \"exclude\",\n",
        "                \"output\": \"atom\",\n",
        "                \"count\": \"1\"\n",
        "            }\n",
        "\n",
        "            response = requests.get(search_url, params=params, headers=self.headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Extract CIK from XML response\n",
        "            # Look for CIK in the response\n",
        "            cik_match = re.search(r'<CIK>(\\d+)</CIK>', response.text)\n",
        "            if cik_match:\n",
        "                cik = cik_match.group(1).zfill(10)\n",
        "                return cik\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not fetch CIK for {ticker}: {e}\")\n",
        "\n",
        "            # Fallback: Use a hardcoded mapping for common tickers\n",
        "            # This is a last resort for well-known companies\n",
        "            common_tickers = {\n",
        "                \"AAPL\": \"0000320193\",\n",
        "                \"MSFT\": \"0000789019\",\n",
        "                \"GOOGL\": \"0001652044\",\n",
        "                \"GOOG\": \"0001652044\",\n",
        "                \"AMZN\": \"0001018724\",\n",
        "                \"TSLA\": \"0001318605\",\n",
        "                \"META\": \"0001326801\",\n",
        "                \"NVDA\": \"0001045810\",\n",
        "                \"JPM\": \"0000019617\",\n",
        "                \"V\": \"0001403161\",\n",
        "                \"IBM\": \"0000051143\",\n",
        "                \"NFLX\": \"0001065280\",\n",
        "                \"DIS\": \"0001001039\",\n",
        "                \"BA\": \"0000012927\",\n",
        "                \"INTC\": \"0000050863\"\n",
        "            }\n",
        "\n",
        "            cik = common_tickers.get(ticker.upper())\n",
        "            if cik:\n",
        "                print(f\"Info: Using cached CIK for {ticker}\")\n",
        "                return cik\n",
        "\n",
        "            return None\n",
        "\n",
        "    def get_filing_content(self, accession_number: str, cik: str) -> str:\n",
        "        \"\"\"\n",
        "        Get the text content of a specific filing\n",
        "        Note: Returns URL - parsing full filing is complex\n",
        "        \"\"\"\n",
        "        accession_no_dashes = accession_number.replace(\"-\", \"\")\n",
        "        url = f\"https://www.sec.gov/cgi-bin/viewer?action=view&cik={cik}&accession_number={accession_number}\"\n",
        "        return url\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting SEC EDGAR Client...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        client = SECEdgarClient()\n",
        "\n",
        "        print(\"\\n1. Testing get_company_submissions('AAPL')...\")\n",
        "        submissions = client.get_company_submissions(\"AAPL\")\n",
        "        print(f\"Company: {submissions['company_name']}\")\n",
        "        print(f\"CIK: {submissions['cik']}\")\n",
        "        print(f\"Total filings: {submissions['total_filings']}\")\n",
        "        print(f\"Recent filings: {len(submissions['recent_filings'])}\")\n",
        "\n",
        "        if submissions['recent_filings']:\n",
        "            latest = submissions['recent_filings'][0]\n",
        "            print(f\"  Latest: {latest['form_type']} on {latest['filing_date']}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"SEC EDGAR Client: READY \")\n",
        "        print(\"\\nNote: SEC enforces rate limits (10 requests/second)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"\\nNote: Ensure proper User-Agent header is set\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de_hQmRdQTWH"
      },
      "source": [
        "## 3. Specialized Agents\n",
        "\n",
        "Our system uses four specialized agents, each focused on a specific aspect of financial analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Models\n",
        "\n",
        "These data models are classes used to hold data that is used by the agents, workflow managers and planners.\n",
        "\n",
        "- **ResearchPlan:** represents an AI-generated research plan from the LLM\n",
        "- **AnalysisResult:** standard format for agent analysis outputs\n",
        "- **AgentMemory:** stores learning across runs\n",
        "- **WorkflowResult:** standard format for workflow outputs\n"
      ],
      "metadata": {
        "id": "wqvToieiK7Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ResearchPlan:\n",
        "    \"\"\"\n",
        "    This class represents an AI-generated research plan from the LLM\n",
        "    The class holds all the data related to the research plan\n",
        "    It's gotten from calls to InvestmentResearchAgent.plan_research()\n",
        "    \"\"\"\n",
        "    stock_symbol: str\n",
        "    objectives: List[str]\n",
        "    data_sources: List[str]\n",
        "    analysis_steps: List[str]\n",
        "    expected_outputs: List[str]\n",
        "    reasoning: str  # LLM's reasoning for the plan\n",
        "    timestamp: str = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.timestamp is None:\n",
        "            self.timestamp = datetime.now().isoformat()\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert to dictionary\"\"\"\n",
        "        return asdict(self)\n",
        "\n",
        "    def summary(self) -> str:\n",
        "        \"\"\"Get human-readable summary\"\"\"\n",
        "        return f\"\"\"\n",
        "Research Plan for {self.stock_symbol}\n",
        "Objectives: {len(self.objectives)} goals\n",
        "Data Sources: {', '.join(self.data_sources)}\n",
        "Analysis Steps: {len(self.analysis_steps)} steps\n",
        "Generated: {self.timestamp}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AnalysisResult:\n",
        "    \"\"\"\n",
        "    Standard format for agent analysis outputs\n",
        "    \"\"\"\n",
        "    agent_name: str\n",
        "    timestamp: str\n",
        "    data_source: str\n",
        "    findings: Dict[str, Any]\n",
        "    confidence_score: float  # 0.0 to 1.0\n",
        "    recommendations: List[str]\n",
        "    llm_reasoning: str  # Full LLM response/reasoning\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if not 0.0 <= self.confidence_score <= 1.0:\n",
        "            raise ValueError(\"Confidence score must be between 0.0 and 1.0\")\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert to dictionary\"\"\"\n",
        "        return asdict(self)\n",
        "\n",
        "    def summary(self) -> str:\n",
        "        \"\"\"Get human-readable summary\"\"\"\n",
        "        return f\"\"\"\n",
        "{self.agent_name} Analysis\n",
        "Confidence: {self.confidence_score:.2f}\n",
        "Recommendations: {len(self.recommendations)}\n",
        "Source: {self.data_source}\n",
        "Timestamp: {self.timestamp}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AgentMemory:\n",
        "    \"\"\"\n",
        "    Stores learning across runs\n",
        "    \"\"\"\n",
        "    stock_symbol: str\n",
        "    timestamp: str\n",
        "    insights: List[str]\n",
        "    quality_scores: Dict[str, float]\n",
        "    recommendations: List[str]\n",
        "    analysis_count: int = 1\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert to dictionary\"\"\"\n",
        "        return asdict(self)\n",
        "\n",
        "    def update_quality(self, new_score: float):\n",
        "        \"\"\"Update quality score with running average\"\"\"\n",
        "        current_avg = self.quality_scores.get(\"overall\", new_score)\n",
        "        self.analysis_count += 1\n",
        "        self.quality_scores[\"overall\"] = (\n",
        "            (current_avg * (self.analysis_count - 1) + new_score) / self.analysis_count\n",
        "        )\n",
        "\n",
        "    def add_insight(self, insight: str):\n",
        "        \"\"\"Add new insight to memory\"\"\"\n",
        "        if insight not in self.insights:\n",
        "            self.insights.append(insight)\n",
        "            # Keep only most recent 10 insights\n",
        "            if len(self.insights) > 10:\n",
        "                self.insights = self.insights[-10:]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WorkflowResult:\n",
        "    \"\"\"\n",
        "    Standard format for workflow outputs\n",
        "    Used by: PromptChainWorkflow, RoutingWorkflow, EvaluatorOptimizerWorkflow\n",
        "    \"\"\"\n",
        "    workflow_name: str\n",
        "    timestamp: str\n",
        "    steps_completed: int\n",
        "    final_output: Any\n",
        "    intermediate_results: List[Dict[str, Any]]\n",
        "    execution_time_seconds: float\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Convert to dictionary\"\"\"\n",
        "        return asdict(self)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing Data Models...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Test ResearchPlan\n",
        "    print(\"\\n1. Testing ResearchPlan...\")\n",
        "    plan = ResearchPlan(\n",
        "        stock_symbol=\"AAPL\",\n",
        "        objectives=[\"Analyze market trends\", \"Evaluate fundamentals\"],\n",
        "        data_sources=[\"Yahoo Finance\", \"Alpha Vantage\"],\n",
        "        analysis_steps=[\"Fetch data\", \"Analyze\", \"Report\"],\n",
        "        expected_outputs=[\"Market analysis\", \"Investment recommendation\"],\n",
        "        reasoning=\"Comprehensive analysis needed for tech stock\"\n",
        "    )\n",
        "    print(f\"Created plan for {plan.stock_symbol}\")\n",
        "    print(plan.summary())\n",
        "\n",
        "    # Test AnalysisResult\n",
        "    print(\"\\n2. Testing AnalysisResult...\")\n",
        "    result = AnalysisResult(\n",
        "        agent_name=\"Market Data Agent\",\n",
        "        timestamp=datetime.now().isoformat(),\n",
        "        data_source=\"Yahoo Finance\",\n",
        "        findings={\"trend\": \"bullish\", \"price\": 175.43},\n",
        "        confidence_score=0.85,\n",
        "        recommendations=[\"Consider buying\", \"Monitor volatility\"],\n",
        "        llm_reasoning=\"Stock shows strong upward momentum\"\n",
        "    )\n",
        "    print(f\"Created analysis with confidence {result.confidence_score}\")\n",
        "    print(result.summary())\n",
        "\n",
        "    # Test AgentMemory\n",
        "    print(\"\\n3. Testing AgentMemory...\")\n",
        "    memory = AgentMemory(\n",
        "        stock_symbol=\"AAPL\",\n",
        "        timestamp=datetime.now().isoformat(),\n",
        "        insights=[\"Strong growth\", \"High valuation\"],\n",
        "        quality_scores={\"overall\": 0.85},\n",
        "        recommendations=[\"Monitor closely\"]\n",
        "    )\n",
        "    memory.add_insight(\"Positive sentiment\")\n",
        "    memory.update_quality(0.90)\n",
        "    print(f\"Created memory with {len(memory.insights)} insights\")\n",
        "    print(f\"  Updated quality: {memory.quality_scores['overall']:.2f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"All data models working!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_RvK5n1KvzG",
        "outputId": "02538207-3b66-4767-85e5-cb9fa5b47780"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Data Models...\n",
            "============================================================\n",
            "\n",
            "1. Testing ResearchPlan...\n",
            "Created plan for AAPL\n",
            "\n",
            "Research Plan for AAPL\n",
            "Objectives: 2 goals\n",
            "Data Sources: Yahoo Finance, Alpha Vantage\n",
            "Analysis Steps: 3 steps\n",
            "Generated: 2025-10-19T22:51:53.350352\n",
            "\n",
            "\n",
            "2. Testing AnalysisResult...\n",
            "Created analysis with confidence 0.85\n",
            "\n",
            "Market Data Agent Analysis\n",
            "Confidence: 0.85\n",
            "Recommendations: 2\n",
            "Source: Yahoo Finance\n",
            "Timestamp: 2025-10-19T22:51:53.350393\n",
            "\n",
            "\n",
            "3. Testing AgentMemory...\n",
            "Created memory with 3 insights\n",
            "  Updated quality: 0.88\n",
            "\n",
            "============================================================\n",
            "All data models working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL95Si3SQTWH"
      },
      "source": [
        "### 3.1 Market Data Agent\n",
        "\n",
        "Analyzes market data, price trends, volatility, valuation and investment recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "3VnYG0OSQTWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ec8391-2dbb-474f-8d2b-8dd86eba9e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Market Data Agent with LLM...\n",
            "============================================================\n",
            "Market Data Agent initialized with LLM\n",
            "\n",
            "Analyzing AAPL with real LLM...\n",
            "\n",
            "[Market Data Agent] Analyzing AAPL with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: bullish\n",
            "\n",
            "============================================================\n",
            "ANALYSIS RESULT:\n",
            "============================================================\n",
            "\n",
            "Market Data Agent Analysis\n",
            "Confidence: 0.85\n",
            "Recommendations: 3\n",
            "Source: Yahoo Finance AOI + OpenAI GPT-4o-mini\n",
            "Timestamp: 2025-10-19T22:51:57.159820\n",
            "\n",
            "\n",
            "FINDINGS:\n",
            "  price_trend: bullish\n",
            "  volatility_assessment: high due to a beta of 1.24, indicating that AAPL is more volatile than the market. The recent price change of +0.69% suggests positive momentum amidst fluctuations.\n",
            "  valuation_opinion: fairly valued, as a PE ratio of 28.5 is in line with industry standards for growth stocks, suggesting that the price reflects the company's earnings potential while considering its strong market position.\n",
            "  technical_position: Currently, AAPL is at 31.9% of its 52-week range, indicating it has room for growth towards the 52-week high of $199.62. The recent price increase from $174.22 to $175.43 indicates bullish sentiment.\n",
            "\n",
            "RECOMMENDATIONS:\n",
            "  1. Consider buying on dips to maximize entry points.\n",
            "  2. Monitor market trends and earnings reports for potential volatility.\n",
            "  3. Evaluate long-term growth potential given technology sector dynamics.\n",
            "\n",
            "============================================================\n",
            "Market Data Agent with LLM: WORKING!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "class MarketDataAgent:\n",
        "    \"\"\"\n",
        "    Agent specialized in market data analysis using LLMs\n",
        "\n",
        "    Analyzes:\n",
        "    - Price trends (bullish/bearish/neutral)\n",
        "    - Volatility assessment\n",
        "    - Valuation opinion\n",
        "    - Investment recommendations\n",
        "\n",
        "    LLM Model: GPT-4o-mini for cost-effective analysis\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm_client: Optional[OpenAI] = None):\n",
        "        self.name = \"Market Data Agent\"\n",
        "\n",
        "        if llm_client is None:\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\n",
        "                    \"OpenAI API key required for LLM agent. \"\n",
        "                    \"Set OPENAI_API_KEY environment variable. \"\n",
        "                    \"Get key at: https://platform.openai.com/api-keys\"\n",
        "                )\n",
        "            self.llm = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.llm = llm_client\n",
        "\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "    def analyze(self, symbol: str, data: Dict[str, Any]) -> AnalysisResult:\n",
        "        \"\"\"\n",
        "        Analyze market data using LLM reasoning\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock ticker symbol\n",
        "            data: Market data from Yahoo Finance\n",
        "\n",
        "        Returns:\n",
        "            AnalysisResult with LLM-powered analysis\n",
        "        \"\"\"\n",
        "        print(f\"\\n[{self.name}] Analyzing {symbol} with LLM...\")\n",
        "\n",
        "        # Prepare comprehensive market prompt for LLM\n",
        "        market_prompt = self._create_market_prompt(symbol, data)\n",
        "\n",
        "        try:\n",
        "            # Call OpenAI LLM for analysis\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert market analyst. Provide analysis in valid JSON format (< 900 characters). Ensure all string values are properly escaped and the JSON is syntactically correct.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": market_prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=500,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            llm_analysis = response.choices[0].message.content\n",
        "\n",
        "            # Parse LLM response\n",
        "            try:\n",
        "                findings = json.loads(llm_analysis)\n",
        "            except json.JSONDecodeError:\n",
        "                # Fallback if JSON parsing fails\n",
        "                findings = {\n",
        "                    \"raw_analysis\": llm_analysis,\n",
        "                    \"price_trend\": \"Analysis provided in raw format\",\n",
        "                    \"recommendations\": [\"Review raw analysis for insights\"]\n",
        "                }\n",
        "\n",
        "            print(f\"  LLM analysis complete\")\n",
        "            print(f\"  Trend: {findings.get('price_trend', 'N/A')}\")\n",
        "\n",
        "            # Extract the recommendations\n",
        "            recommendations = findings.get(\"recommendations\", [])\n",
        "            if isinstance(recommendations, str):\n",
        "                recommendations = [recommendations]\n",
        "\n",
        "            return AnalysisResult(\n",
        "                agent_name=self.name,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                data_source=\"Yahoo Finance AOI + OpenAI GPT-4o-mini\",\n",
        "                findings=findings,\n",
        "                confidence_score=0.85,\n",
        "                recommendations=recommendations,\n",
        "                llm_reasoning=llm_analysis\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  LLM analysis error: {str(e)}\")\n",
        "            raise RuntimeError(f\"Failed to analyze with LLM: {str(e)}\")\n",
        "\n",
        "    def _create_market_prompt(self, symbol: str, data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Create comprehensive prompt for LLM analysis\"\"\"\n",
        "\n",
        "        # Extract key metrics with safe defaults\n",
        "        company = data.get('company_name', 'N/A')\n",
        "        sector = data.get('sector', 'N/A')\n",
        "        current_price = data.get('current_price', 0)\n",
        "        prev_close = data.get('previous_close', 0)\n",
        "        market_cap = data.get('market_cap', 0)\n",
        "        pe_ratio = data.get('pe_ratio', 'N/A')\n",
        "        week_52_high = data.get('52_week_high', 0)\n",
        "        week_52_low = data.get('52_week_low', 0)\n",
        "        beta = data.get('beta', 'N/A')\n",
        "        volume = data.get('volume', 0)\n",
        "\n",
        "        # Calculate price change\n",
        "        price_change = current_price - prev_close if current_price and prev_close else 0\n",
        "        price_change_pct = (price_change / prev_close * 100) if prev_close else 0\n",
        "\n",
        "        # Calculate position in 52-week range\n",
        "        if week_52_high and week_52_low and week_52_high > week_52_low:\n",
        "            range_position = ((current_price - week_52_low) / (week_52_high - week_52_low)) * 100\n",
        "        else:\n",
        "            range_position = None\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an expert market analyst. Analyze this stock's market data and provide investment insights.\n",
        "\n",
        "STOCK INFORMATION:\n",
        "Symbol: {symbol}\n",
        "Company: {company}\n",
        "Sector: {sector}\n",
        "\n",
        "PRICE METRICS:\n",
        "Current Price: ${current_price:.2f}\n",
        "Previous Close: ${prev_close:.2f}\n",
        "Price Change: ${price_change:.2f} ({price_change_pct:+.2f}%)\n",
        "52-Week High: ${week_52_high:.2f}\n",
        "52-Week Low: ${week_52_low:.2f}\n",
        "52-Week Range Position: {f\"{range_position:.1f}%\" if range_position else \"N/A\"}\n",
        "\n",
        "VALUATION & RISK:\n",
        "Market Cap: ${market_cap:,}\n",
        "PE Ratio: {pe_ratio}\n",
        "Beta (Volatility): {beta}\n",
        "Volume: {volume:,}\n",
        "\n",
        "ANALYSIS REQUIRED:\n",
        "Provide your analysis in JSON format with these fields:\n",
        "{{\n",
        "    \"price_trend\": \"bullish/bearish/neutral with 2-3 sentence explanation\",\n",
        "    \"volatility_assessment\": \"high/moderate/low with reasoning based on beta and price action\",\n",
        "    \"valuation_opinion\": \"overvalued/undervalued/fairly valued with reasoning based on PE and market position\",\n",
        "    \"technical_position\": \"analysis of 52-week range position and recent price action\",\n",
        "    \"key_observations\": [\"observation 1\", \"observation 2\", \"observation 3\"],\n",
        "    \"recommendations\": [\"specific recommendation 1\", \"specific recommendation 2\", \"specific recommendation 3\"]\n",
        "}}\n",
        "\n",
        "Be specific, data-driven, and actionable. Focus on the metrics provided.\n",
        "\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Market Data Agent with LLM...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Check for API key\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY not set\")\n",
        "        print(\"\\nSet your OpenAI API key:\")\n",
        "        print(\"  export OPENAI_API_KEY=sk-your-key-here\")\n",
        "        print(\"\\nGet key at: https://platform.openai.com/api-keys\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        # Initialize agent\n",
        "        agent = MarketDataAgent()\n",
        "\n",
        "        # Test data\n",
        "        test_data = {\n",
        "            \"symbol\": \"AAPL\",\n",
        "            \"company_name\": \"Apple Inc.\",\n",
        "            \"sector\": \"Technology\",\n",
        "            \"current_price\": 175.43,\n",
        "            \"previous_close\": 174.22,\n",
        "            \"market_cap\": 2750000000000,\n",
        "            \"pe_ratio\": 28.5,\n",
        "            \"52_week_high\": 199.62,\n",
        "            \"52_week_low\": 164.08,\n",
        "            \"beta\": 1.24,\n",
        "            \"volume\": 52000000\n",
        "        }\n",
        "\n",
        "        print(\"\\nAnalyzing AAPL with real LLM...\")\n",
        "        result = agent.analyze(\"AAPL\", test_data)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ANALYSIS RESULT:\")\n",
        "        print(\"=\"*60)\n",
        "        print(result.summary())\n",
        "\n",
        "        print(\"\\nFINDINGS:\")\n",
        "        for key, value in result.findings.items():\n",
        "            if key != \"recommendations\" and key != \"key_observations\":\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        print(\"\\nRECOMMENDATIONS:\")\n",
        "        for i, rec in enumerate(result.recommendations, 1):\n",
        "            print(f\"  {i}. {rec}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Market Data Agent with LLM: WORKING!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "        print(\"\\nMake sure:\")\n",
        "        print(\"  1. OPENAI_API_KEY is set\")\n",
        "        print(\"  2. API key is valid\")\n",
        "        print(\"  3. You have API credits\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk6VaDLGQTWH"
      },
      "source": [
        "### 3.2 Fundamentals Agent\n",
        "\n",
        "Analyzes fundamentals: Profitability (margins, ROE), Growth potential, Financial health, Competitive position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "B3F8ubJQQTWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326a0867-0ddc-4129-cb42-cd495ee358c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Additional LLM Agents...\n",
            "============================================================\n",
            "\n",
            "1. Testing Fundamentals Agent...\n",
            "Fundamentals Agent initialized with LLM\n",
            "\n",
            "[Fundamentals Agent] Analyzing AAPL fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  Analysis complete\n",
            "    Findings: 8 metrics\n",
            "    Recommendations: 3\n"
          ]
        }
      ],
      "source": [
        "class FundamentalsAgent:\n",
        "    \"\"\"\n",
        "    Agent specialized in fundamental analysis using LLMs\n",
        "\n",
        "    Analyzes:\n",
        "    - Profitability (margins, ROE)\n",
        "    - Growth potential\n",
        "    - Financial health\n",
        "    - Competitive position\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm_client: Optional[OpenAI] = None):\n",
        "        self.name = \"Fundamentals Agent\"\n",
        "\n",
        "        if llm_client is None:\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"OpenAI API key required\")\n",
        "            self.llm = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.llm = llm_client\n",
        "\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "    def analyze(self, symbol: str, data: Dict[str, Any]) -> AnalysisResult:\n",
        "        \"\"\"Analyze fundamental data using LLM\"\"\"\n",
        "        print(f\"\\n[{self.name}] Analyzing {symbol} fundamentals with LLM...\")\n",
        "\n",
        "        prompt = self._create_fundamentals_prompt(symbol, data)\n",
        "\n",
        "        try:\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert fundamental analyst. Provide analysis in valid JSON format (< 900 characters). Ensure all string values are properly escaped and the JSON is syntactically correct.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.6,\n",
        "                max_tokens=1000,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            llm_analysis = response.choices[0].message.content\n",
        "            findings = json.loads(llm_analysis)\n",
        "\n",
        "            print(f\"  Fundamentals analysis complete\")\n",
        "\n",
        "            return AnalysisResult(\n",
        "                agent_name=self.name,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                data_source=\"Yahoo Finance + Alpha Vantage + OpenAI\",\n",
        "                findings=findings,\n",
        "                confidence_score=0.82,\n",
        "                recommendations=findings.get(\"recommendations\", []),\n",
        "                llm_reasoning=llm_analysis\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _create_fundamentals_prompt(self, symbol: str, data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Create prompt for fundamental analysis\"\"\"\n",
        "\n",
        "        company = data.get('company_name', 'N/A')\n",
        "        revenue = data.get('revenue', 0)\n",
        "        profit_margin = data.get('profit_margin', 0)\n",
        "        operating_margin = data.get('operating_margin', 0)\n",
        "        earnings_growth = data.get('earnings_growth', 0)\n",
        "        pe_ratio = data.get('pe_ratio', 'N/A')\n",
        "        forward_pe = data.get('forward_pe', 'N/A')\n",
        "        debt_to_equity = data.get('debt_to_equity', 'N/A')\n",
        "        roe = data.get('return_on_equity', 'N/A')\n",
        "\n",
        "        return f\"\"\"\n",
        "Analyze the fundamental financial health of this company:\n",
        "\n",
        "COMPANY: {symbol} - {company}\n",
        "\n",
        "PROFITABILITY:\n",
        "Revenue (TTM): ${revenue:,}\n",
        "Profit Margin: {profit_margin:.2%} if profit_margin else \"N/A\"\n",
        "Operating Margin: {operating_margin:.2%} if operating_margin else \"N/A\"\n",
        "Return on Equity: {roe}\n",
        "\n",
        "VALUATION:\n",
        "PE Ratio (Trailing): {pe_ratio}\n",
        "PE Ratio (Forward): {forward_pe}\n",
        "\n",
        "GROWTH:\n",
        "Earnings Growth: {earnings_growth:.2%} if earnings_growth else \"N/A\"\n",
        "\n",
        "FINANCIAL STRENGTH:\n",
        "Debt-to-Equity: {debt_to_equity}\n",
        "\n",
        "Provide valid JSON analysis:\n",
        "{{\n",
        "    \"profitability_assessment\": \"strong/moderate/weak with detailed explanation\",\n",
        "    \"growth_potential\": \"high/moderate/low with reasoning and growth trajectory\",\n",
        "    \"financial_health\": \"excellent/good/fair/poor with balance sheet analysis\",\n",
        "    \"competitive_position\": \"market leader/strong/average/weak with reasoning\",\n",
        "    \"valuation_summary\": \"analysis of PE ratios and valuation metrics\",\n",
        "    \"key_strengths\": [\"strength 1\", \"strength 2\", \"strength 3\"],\n",
        "    \"key_concerns\": [\"concern 1\", \"concern 2\"],\n",
        "    \"recommendations\": [\"actionable recommendation 1\", \"recommendation 2\", \"recommendation 3\"]\n",
        "}}\n",
        "\n",
        "Be specific and data-driven.\n",
        "\"\"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "\n",
        "    print(\"\\nTesting Additional LLM Agents...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY not set\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Test Fundamentals Agent\n",
        "    print(\"\\n1. Testing Fundamentals Agent...\")\n",
        "    try:\n",
        "        fund_agent = FundamentalsAgent()\n",
        "\n",
        "        test_data = {\n",
        "            \"company_name\": \"Apple Inc.\",\n",
        "            \"revenue\": 385000000000,\n",
        "            \"profit_margin\": 0.25,\n",
        "            \"operating_margin\": 0.30,\n",
        "            \"earnings_growth\": 0.08,\n",
        "            \"pe_ratio\": 28.5,\n",
        "            \"forward_pe\": 26.0,\n",
        "            \"return_on_equity\": 0.45,\n",
        "            \"debt_to_equity\": 1.5\n",
        "        }\n",
        "\n",
        "        result = fund_agent.analyze(\"AAPL\", test_data)\n",
        "        print(f\"  Analysis complete\")\n",
        "        print(f\"    Findings: {len(result.findings)} metrics\")\n",
        "        print(f\"    Recommendations: {len(result.recommendations)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gci0CFSfQTWI"
      },
      "source": [
        "### 3.3 Economic Context Agent\n",
        "Analyzes macroeconomic conditions and sector implications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "cO8hTKToQTWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3b51be-a269-4b2c-e9dd-7563413249ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Additional LLM Agents...\n",
            "============================================================\n",
            "\n",
            "Testing Economic Context Agent...\n",
            "Economic Context Agent initialized with LLM\n",
            "\n",
            "[Economic Context Agent] Analyzing Technology sector economic context...\n",
            "  Economic analysis complete\n",
            "  Analysis complete\n",
            "    Sector: Technology\n",
            "    Recommendations: 3\n",
            "\n",
            "============================================================\n",
            "Additional LLM Agents: WORKING!\n"
          ]
        }
      ],
      "source": [
        "class EconomicContextAgent:\n",
        "    \"\"\"\n",
        "    Agent specialized in economic context analysis using LLMs\n",
        "\n",
        "    Analyzes:\n",
        "    - Interest rate impact\n",
        "    - Employment conditions\n",
        "    - Sector outlook\n",
        "    - Macroeconomic risks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm_client: Optional[OpenAI] = None):\n",
        "        self.name = \"Economic Context Agent\"\n",
        "\n",
        "        if llm_client is None:\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"OpenAI API key required\")\n",
        "            self.llm = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.llm = llm_client\n",
        "\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "    def analyze(self, sector: str, economic_data: Dict[str, Any]) -> AnalysisResult:\n",
        "        \"\"\"Analyze economic context using LLM\"\"\"\n",
        "        print(f\"\\n[{self.name}] Analyzing {sector} sector economic context...\")\n",
        "\n",
        "        prompt = self._create_economic_prompt(sector, economic_data)\n",
        "\n",
        "        try:\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert macroeconomic analyst. Provide analysis in valid JSON format (< 900 characters). Ensure all string values are properly escaped and the JSON is syntactically correct.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.5,\n",
        "                max_tokens=1000,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            llm_analysis = response.choices[0].message.content\n",
        "            findings = json.loads(llm_analysis)\n",
        "\n",
        "            print(f\"  Economic analysis complete\")\n",
        "\n",
        "            return AnalysisResult(\n",
        "                agent_name=self.name,\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                data_source=\"FRED + OpenAI\",\n",
        "                findings=findings,\n",
        "                confidence_score=0.85,\n",
        "                recommendations=findings.get(\"recommendations\", []),\n",
        "                llm_reasoning=llm_analysis\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _create_economic_prompt(self, sector: str, data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Create prompt for economic analysis\"\"\"\n",
        "\n",
        "        fed_rate = data.get('fed_funds_rate', 'N/A')\n",
        "        unemployment = data.get('unemployment_rate', 'N/A')\n",
        "        cpi = data.get('cpi', 'N/A')\n",
        "        gdp_growth = data.get('gdp_growth', 'N/A')\n",
        "\n",
        "        return f\"\"\"\n",
        "Analyze how current macroeconomic conditions affect the {sector} sector:\n",
        "\n",
        "ECONOMIC INDICATORS:\n",
        "Federal Funds Rate: {fed_rate}%\n",
        "Unemployment Rate: {unemployment}%\n",
        "CPI (Inflation): {cpi}\n",
        "GDP Growth: {gdp_growth}\n",
        "\n",
        "TARGET SECTOR: {sector}\n",
        "\n",
        "Strictly provide valid JSON analysis:\n",
        "{{\n",
        "    \"interest_rate_impact\": \"positive/negative/neutral with detailed explanation of rate effects on {sector}\",\n",
        "    \"employment_impact\": \"analysis of how employment trends affect {sector} demand and operations\",\n",
        "    \"inflation_impact\": \"how inflation affects {sector} costs, pricing power, and margins\",\n",
        "    \"sector_outlook\": \"favorable/neutral/challenging with 3-6 month outlook for {sector}\",\n",
        "    \"cyclical_analysis\": \"where we are in economic cycle and {sector} positioning\",\n",
        "    \"key_risks\": [\"macroeconomic risk 1\", \"risk 2\", \"risk 3\"],\n",
        "    \"key_opportunities\": [\"opportunity 1\", \"opportunity 2\"],\n",
        "    \"recommendations\": [\"sector-specific recommendation 1\", \"recommendation 2\", \"recommendation 3\"]\n",
        "}}\n",
        "\n",
        "Focus on sector-specific impacts. Be specific about transmission mechanisms.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "\n",
        "    print(\"\\nTesting Additional LLM Agents...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY not set\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Test Economic Agent\n",
        "    print(\"\\nTesting Economic Context Agent...\")\n",
        "    try:\n",
        "        econ_agent = EconomicContextAgent()\n",
        "\n",
        "        econ_data = {\n",
        "            \"fed_funds_rate\": 5.33,\n",
        "            \"unemployment_rate\": 3.8,\n",
        "            \"cpi\": 310.5,\n",
        "            \"gdp_growth\": 2.5\n",
        "        }\n",
        "\n",
        "        result = econ_agent.analyze(\"Technology\", econ_data)\n",
        "        print(f\"  Analysis complete\")\n",
        "        print(f\"    Sector: Technology\")\n",
        "        print(f\"    Recommendations: {len(result.recommendations)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Additional LLM Agents: WORKING!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWun2CpqQTWI"
      },
      "source": [
        "### 3.4 Regulatory Agent\n",
        "Analyzes SEC filings and regulatory compliance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "JjUzsEhoQTWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fb857f-c041-47e9-ec9a-ed044a0e5937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing All Agents...\n",
            "============================================================\n",
            "\n",
            "3. Testing Regulatory Agent (no LLM)...\n",
            "Regulatory Agent initialized\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for AAPL...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "  Analysis complete\n",
            "    CIK: 0000320193\n",
            "    Status: Current\n",
            "\n",
            "============================================================\n",
            "ALL 4 SPECIALIZED AGENTS COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Agents created:\n",
            "  1. MarketDataAgent (LLM)\n",
            "  2. FundamentalsAgent (LLM)\n",
            "  3. EconomicContextAgent (LLM)\n",
            "  4. RegulatoryAgent (Structured)\n"
          ]
        }
      ],
      "source": [
        "class RegulatoryAgent:\n",
        "    \"\"\"\n",
        "    Agent specialized in regulatory compliance analysis\n",
        "    Simpler agent - uses structured data without LLM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.name = \"Regulatory Agent\"\n",
        "        print(f\"{self.name} initialized\")\n",
        "\n",
        "    def analyze(self, symbol: str, filings_data: Dict[str, Any]) -> AnalysisResult:\n",
        "        \"\"\"Analyze regulatory filings\"\"\"\n",
        "        print(f\"\\n[{self.name}] Analyzing regulatory status for {symbol}...\")\n",
        "\n",
        "        # Extract filing information\n",
        "        recent_filings = filings_data.get(\"recent_filings\", [])\n",
        "        total_filings = filings_data.get(\"total_filings\", 0)\n",
        "        cik = filings_data.get(\"cik\", \"Unknown\")\n",
        "\n",
        "        # Analyze compliance\n",
        "        findings = {\n",
        "            \"cik\": cik,\n",
        "            \"total_filings\": total_filings,\n",
        "            \"recent_filings_count\": len(recent_filings),\n",
        "            \"filing_types\": list(set([f.get(\"form_type\", \"\") for f in recent_filings[:10]])),\n",
        "            \"latest_filing\": recent_filings[0] if recent_filings else None,\n",
        "            \"compliance_status\": \"Current\" if recent_filings else \"Unknown\"\n",
        "        }\n",
        "\n",
        "        # Generate recommendations\n",
        "        recommendations = [\n",
        "            f\"Company maintains {findings['compliance_status']} SEC filings (CIK: {cik})\",\n",
        "            f\"Total filings on record: {total_filings}\",\n",
        "            \"Review recent 10-K for annual details\",\n",
        "            \"Review recent 10-Q for quarterly updates\"\n",
        "        ]\n",
        "\n",
        "        if findings[\"latest_filing\"]:\n",
        "            latest = findings[\"latest_filing\"]\n",
        "            recommendations.insert(0,\n",
        "                f\"Latest filing: {latest.get('form_type')} on {latest.get('filing_date')}\"\n",
        "            )\n",
        "\n",
        "        print(f\"  Regulatory analysis complete\")\n",
        "        print(f\"    Status: {findings['compliance_status']}\")\n",
        "\n",
        "        return AnalysisResult(\n",
        "            agent_name=self.name,\n",
        "            timestamp=datetime.now().isoformat(),\n",
        "            data_source=\"SEC EDGAR\",\n",
        "            findings=findings,\n",
        "            confidence_score=0.70,\n",
        "            recommendations=recommendations,\n",
        "            llm_reasoning=\"Structured analysis of SEC filings data\"\n",
        "        )\n",
        "\n",
        "\n",
        "# Test all agents\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting All Agents...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY not set - LLM agents will fail\")\n",
        "        print(\"Regulatory agent will work (doesn't use LLM)\")\n",
        "\n",
        "    # Test Regulatory Agent (no LLM needed)\n",
        "    print(\"\\n3. Testing Regulatory Agent (no LLM)...\")\n",
        "    try:\n",
        "        reg_agent = RegulatoryAgent()\n",
        "\n",
        "        test_filings = {\n",
        "            \"cik\": \"0000320193\",\n",
        "            \"total_filings\": 1250,\n",
        "            \"recent_filings\": [\n",
        "                {\"form_type\": \"10-K\", \"filing_date\": \"2024-10-25\"},\n",
        "                {\"form_type\": \"10-Q\", \"filing_date\": \"2024-07-28\"},\n",
        "                {\"form_type\": \"8-K\", \"filing_date\": \"2024-06-15\"}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        result = reg_agent.analyze(\"AAPL\", test_filings)\n",
        "        print(f\"  Analysis complete\")\n",
        "        print(f\"    CIK: {result.findings['cik']}\")\n",
        "        print(f\"    Status: {result.findings['compliance_status']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ALL 4 SPECIALIZED AGENTS COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nAgents created:\")\n",
        "    print(\"  1. MarketDataAgent (LLM)\")\n",
        "    print(\"  2. FundamentalsAgent (LLM)\")\n",
        "    print(\"  3. EconomicContextAgent (LLM)\")\n",
        "    print(\"  4. RegulatoryAgent (Structured)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaPpDxILQTWI"
      },
      "source": [
        "## 4. Workflow Pattern 1: Prompt Chaining\n",
        "\n",
        "Demonstrates sequential processing: **Ingest → Preprocess → Classify → Extract → Summarize**\n",
        "\n",
        "- **Ingest:** Collects raw market data from the API clients.\n",
        "- **Preprocess:** Structures and cleans data.\n",
        "- **Classify:** Categorizes by data type.\n",
        "- **Extract:** Extract insights using LLM, focussing on Market positioning and trends, Financial health indicators, and Investment opportunities or risks.\n",
        "- **Summarize:** Creates final summary using LLM into a concise executive summary.\n",
        "\n",
        "This pattern shows how data flows through multiple transformation stages to produce refined insights.\n",
        "\n",
        "![Prompt Chain Workflow](https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Prompt%20Chain%20Workflow.png)\n",
        "\n",
        "For example:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Prompt%20Chain%20Workflow%20AAPL%20Example.png\" height=\"700\" style=\"display: block; margin: 0 auto;\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "2h__kC3IQTWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3ebe1e-b67b-4b66-e3d3-305aea387df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Prompt Chain Workflow...\n",
            "============================================================\n",
            "Prompt Chain Workflow initialized with LLM\n",
            "\n",
            "[Prompt Chain Workflow] Executing for AAPL...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 4.16s\n",
            "\n",
            "============================================================\n",
            "WORKFLOW RESULT:\n",
            "============================================================\n",
            "Steps completed: 5\n",
            "Execution time: 4.16s\n",
            "\n",
            "Final Summary:\n",
            "Apple Inc. (AAPL) maintains its leadership in the premium smartphone market, bolstered by strong brand loyalty and a growing services segment that enhances revenue diversification and stability. Despite robust financial health characterized by rising margins and strong cash flow, investors should remain vigilant regarding potential supply chain vulnerabilities due to geopolitical tensions. Continued investments in R&D and sustainability initiatives further position Apple favorably for future growth.\n",
            "\n",
            "============================================================\n",
            "Prompt Chain Workflow: WORKING! \n"
          ]
        }
      ],
      "source": [
        "class PromptChainWorkflow:\n",
        "    \"\"\"\n",
        "    Workflow Pattern 1: Prompt Chaining with LLM\n",
        "\n",
        "    5-Step Pipeline:\n",
        "    1. Ingest data\n",
        "    2. Preprocess and structure\n",
        "    3. Classify data types\n",
        "    4. Extract insights (LLM-powered)\n",
        "    5. Summarize findings (LLM-powered)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm_client: Optional[OpenAI] = None):\n",
        "        self.name = \"Prompt Chain Workflow\"\n",
        "\n",
        "        if llm_client is None:\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"OpenAI API key required for workflow\")\n",
        "            self.llm = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.llm = llm_client\n",
        "\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "    def execute(self, symbol: str, data: Dict[str, Any]) -> WorkflowResult:\n",
        "        \"\"\"Execute 5-step prompt chain workflow Each step takes the output of hte previous step.\"\"\"\n",
        "        print(f\"\\n[{self.name}] Executing for {symbol}...\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        intermediate_results = []\n",
        "\n",
        "        print(\"  [Step 1/5] Ingesting data...\")\n",
        "        ingested = self._step1_ingest(data)\n",
        "        intermediate_results.append({\"step\": 1, \"name\": \"Ingest\", \"output\": \"Data ingested\"})\n",
        "\n",
        "        print(\"  [Step 2/5] Preprocessing...\")\n",
        "        preprocessed = self._step2_preprocess(ingested, symbol)\n",
        "        intermediate_results.append({\"step\": 2, \"name\": \"Preprocess\", \"output\": \"Data structured\"})\n",
        "\n",
        "        print(\"  [Step 3/5] Classifying...\")\n",
        "        classified = self._step3_classify(preprocessed)\n",
        "        intermediate_results.append({\"step\": 3, \"name\": \"Classify\", \"output\": \"Data classified\"})\n",
        "\n",
        "        print(\"  [Step 4/5] Extracting insights with LLM...\")\n",
        "        insights = self._step4_extract_insights_llm(classified, symbol)\n",
        "        intermediate_results.append({\"step\": 4, \"name\": \"Extract (LLM)\", \"output\": insights})\n",
        "\n",
        "        print(\"  [Step 5/5] Synthesizing summary with LLM...\")\n",
        "        summary = self._step5_summarize_llm(insights, symbol)\n",
        "        intermediate_results.append({\"step\": 5, \"name\": \"Summarize (LLM)\", \"output\": summary})\n",
        "\n",
        "        execution_time = time.time() - start_time\n",
        "\n",
        "        print(f\"  Workflow complete in {execution_time:.2f}s\")\n",
        "\n",
        "        return WorkflowResult(\n",
        "            workflow_name=self.name,\n",
        "            timestamp=datetime.now().isoformat(),\n",
        "            steps_completed=5,\n",
        "            final_output=summary,\n",
        "            intermediate_results=intermediate_results,\n",
        "            execution_time_seconds=execution_time\n",
        "        )\n",
        "\n",
        "    def _step1_ingest(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Step 1: Ingest raw data\"\"\"\n",
        "        return {\"raw_data\": data, \"ingested_at\": datetime.now().isoformat()}\n",
        "\n",
        "    def _step2_preprocess(self, data: Dict[str, Any], symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"Step 2: Preprocess and structure\"\"\"\n",
        "        return {\n",
        "            \"symbol\": symbol,\n",
        "            \"structured_data\": data.get(\"raw_data\", {}),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    def _step3_classify(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Step 3: Classify data into categories\"\"\"\n",
        "        return {\n",
        "            \"symbol\": data.get(\"symbol\"),\n",
        "            \"categories\": {\n",
        "                \"market_data\": True,\n",
        "                \"fundamental_data\": True,\n",
        "                \"economic_context\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _step4_extract_insights_llm(self, classified: Dict[str, Any], symbol: str) -> List[str]:\n",
        "        \"\"\"Step 4: Extract insights using LLM\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Based on financial analysis of {symbol}, extract 3-5 key investment insights.\n",
        "\n",
        "Focus on:\n",
        "- Market positioning and trends\n",
        "- Financial health indicators\n",
        "- Investment opportunities or risks\n",
        "\n",
        "Provide insights as a JSON array of strings:\n",
        "{{\"insights\": [\"insight 1\", \"insight 2\", \"insight 3\"]}}\n",
        "\n",
        "Be specific and actionable.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a financial analyst extracting key insights.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=300,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            result = json.loads(response.choices[0].message.content)\n",
        "            insights = result.get(\"insights\", [])\n",
        "\n",
        "            return insights if insights else [\n",
        "                f\"Market analysis completed for {symbol}\",\n",
        "                \"Financial metrics evaluated\",\n",
        "                \"Investment considerations identified\"\n",
        "            ]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Warning: LLM extraction error: {e}\")\n",
        "            return [\n",
        "                f\"Analysis completed for {symbol}\",\n",
        "                \"Key metrics evaluated\",\n",
        "                \"Investment factors assessed\"\n",
        "            ]\n",
        "\n",
        "    def _step5_summarize_llm(self, insights: List[str], symbol: str) -> str:\n",
        "        \"\"\"Step 5: Synthesize summary using LLM\"\"\"\n",
        "\n",
        "        insights_text = \"\\n\".join(f\"- {insight}\" for insight in insights)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Synthesize these investment insights for {symbol} into a concise executive summary (2-3 sentences):\n",
        "\n",
        "{insights_text}\n",
        "\n",
        "Provide a clear, actionable summary for investors in JSON format:\n",
        "{{\"summary\": \"your executive summary here\"}}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a financial analyst creating executive summaries.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=200,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            result = json.loads(response.choices[0].message.content)\n",
        "            summary = result.get(\"summary\", \"\")\n",
        "\n",
        "            return summary if summary else f\"Analysis of {symbol} reveals {len(insights)} key insights for investors.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Warning: LLM summary error: {e}\")\n",
        "            return f\"Investment analysis for {symbol} completed. Key insights: {', '.join(insights[:2])}.\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Prompt Chain Workflow...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY not set\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        workflow = PromptChainWorkflow()\n",
        "\n",
        "        test_data = {\n",
        "            \"symbol\": \"AAPL\",\n",
        "            \"price\": 175.43,\n",
        "            \"market_cap\": 2750000000000\n",
        "        }\n",
        "\n",
        "        result = workflow.execute(\"AAPL\", test_data)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"WORKFLOW RESULT:\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Steps completed: {result.steps_completed}\")\n",
        "        print(f\"Execution time: {result.execution_time_seconds:.2f}s\")\n",
        "        print(f\"\\nFinal Summary:\\n{result.final_output}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Prompt Chain Workflow: WORKING! \")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gswl3ht8QTWI"
      },
      "source": [
        "## 5. Workflow Pattern 2: Routing\n",
        "\n",
        "Demonstrates intelligent routing to specialized agents based on query type.\n",
        "\n",
        "The router analyzes the request and directs it to the most appropriate specialist agent.\n",
        "\n",
        "![Routing Workflow](https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Routing%20Workflow%20-%20Overview.png)\n",
        "\n",
        "**Sequence Diagram**\n",
        "\n",
        "A typical flow looks like the sequence diagram below, we can see a query reasoned to be about Fundamentals and passed to the Fundamentals Agent which performs the analysis.\n",
        "\n",
        "![Routing Workflow Sequence Diagram](https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Routing%20Workflow%20-%20Sequence%20Diagram.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "2oXawW60QTWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6a69da-a09e-43bb-db33-1a33749ad233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Routing Workflow Patterns...\n",
            "============================================================\n",
            "Routing Workflow initialized with LLM\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the current stock price trend?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks about the current stock price tr...\n",
            "  Query: What's the current stock price trend?\n",
            "  → Routed to: MarketDataAgent\n",
            "\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: How profitable is the company?...\n",
            "  Routed to: FundamentalsAgent\n",
            "  Reasoning: The query specifically asks about the profitability of the c...\n",
            "  Query: How profitable is the company?\n",
            "  → Routed to: FundamentalsAgent\n",
            "\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What are the current interest rates?...\n",
            "  Routed to: EconomicContextAgent\n",
            "  Reasoning: Interest rates are influenced by macroeconomic factors such ...\n",
            "  Query: What are the current interest rates?\n",
            "  → Routed to: EconomicContextAgent\n",
            "\n",
            "  Routing workflow working\n"
          ]
        }
      ],
      "source": [
        "class RoutingWorkflow:\n",
        "    \"\"\"\n",
        "    Workflow Pattern 2: Intelligent Routing with LLM\n",
        "\n",
        "    LLM analyzes query and routes to appropriate specialist agent\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm_client: Optional[OpenAI] = None):\n",
        "        self.name = \"Routing Workflow\"\n",
        "\n",
        "        if llm_client is None:\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"OpenAI API key required\")\n",
        "            self.llm = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.llm = llm_client\n",
        "\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "    def execute(self, query: str, available_agents: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Route query to appropriate agent using LLM\n",
        "\n",
        "        Args:\n",
        "            query: User's analysis request\n",
        "            available_agents: List of agent names\n",
        "\n",
        "        Returns:\n",
        "            Routing decision with reasoning\n",
        "        \"\"\"\n",
        "        print(f\"\\n[{self.name}] Routing query with LLM...\")\n",
        "        print(f\"  Query: {query[:60]}...\")\n",
        "\n",
        "        prompt = self._create_routing_prompt(query, available_agents)\n",
        "\n",
        "        try:\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a query routing expert.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=150,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            routing_decision = json.loads(response.choices[0].message.content)\n",
        "            selected_agent = routing_decision.get(\"selected_agent\", available_agents[0])\n",
        "            reasoning = routing_decision.get(\"reasoning\", \"Agent selected\")\n",
        "\n",
        "            print(f\"  Routed to: {selected_agent}\")\n",
        "            print(f\"  Reasoning: {reasoning[:60]}...\")\n",
        "\n",
        "            return {\n",
        "                \"query\": query,\n",
        "                \"selected_agent\": selected_agent,\n",
        "                \"reasoning\": reasoning,\n",
        "                \"available_agents\": available_agents,\n",
        "                \"routing_method\": \"LLM-powered\",\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Warning: Routing error: {e}\")\n",
        "            return {\n",
        "                \"query\": query,\n",
        "                \"selected_agent\": available_agents[0],\n",
        "                \"reasoning\": \"Fallback routing\",\n",
        "                \"routing_method\": \"fallback\"\n",
        "            }\n",
        "\n",
        "    def _create_routing_prompt(self, query: str, agents: List[str]) -> str:\n",
        "        \"\"\"Create routing prompt\"\"\"\n",
        "\n",
        "        agent_descriptions = {\n",
        "            \"MarketDataAgent\": \"Analyzes price trends, volatility, market conditions\",\n",
        "            \"FundamentalsAgent\": \"Analyzes profitability, growth, financial health\",\n",
        "            \"EconomicContextAgent\": \"Analyzes macroeconomic factors, sector outlook\",\n",
        "            \"RegulatoryAgent\": \"Analyzes SEC filings, compliance status\"\n",
        "        }\n",
        "\n",
        "        agents_info = \"\\n\".join([\n",
        "            f\"- {agent}: {agent_descriptions.get(agent, 'Financial analysis')}\"\n",
        "            for agent in agents\n",
        "        ])\n",
        "\n",
        "        return f\"\"\"\n",
        "Route this financial analysis query to the most appropriate specialist agent:\n",
        "\n",
        "Query: \"{query}\"\n",
        "\n",
        "Available agents:\n",
        "{agents_info}\n",
        "\n",
        "Select ONE agent and provide reasoning in JSON format:\n",
        "{{\n",
        "    \"selected_agent\": \"AgentName\",\n",
        "    \"reasoning\": \"brief explanation why this agent is most suitable\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Routing Workflow Patterns...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"✗ OPENAI_API_KEY not set\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        router = RoutingWorkflow()\n",
        "\n",
        "        test_queries = [\n",
        "            \"What's the current stock price trend?\",\n",
        "            \"How profitable is the company?\",\n",
        "            \"What are the current interest rates?\"\n",
        "        ]\n",
        "\n",
        "        for query in test_queries:\n",
        "            result = router.execute(\n",
        "                query,\n",
        "                [\"MarketDataAgent\", \"FundamentalsAgent\", \"EconomicContextAgent\"]\n",
        "            )\n",
        "            print(f\"  Query: {query}\")\n",
        "            print(f\"  → Routed to: {result['selected_agent']}\\n\")\n",
        "\n",
        "        print(\"  Routing workflow working\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KpPeG9xQTWI"
      },
      "source": [
        "## 6. Workflow Pattern 3: Evaluator-Optimizer\n",
        "\n",
        "Demonstrates iterative refinement: **Generate → Evaluate → Optimize**\n",
        "\n",
        "The system generates analysis, evaluates quality, and refines output until quality thresholds are met.\n",
        "\n",
        "- **Generate:** Creates comprehensive analysis\n",
        "- **Evaluate:** Scores quality (completeness, confidence)\n",
        "- **Optimize:** Refines based on feedback\n",
        "- Iterates up to 3 times until quality threshold (0.8) met\n",
        "\n",
        "Quality is scored on:\n",
        "\n",
        "- Completeness\n",
        "- Accuracy\n",
        "- Depth\n",
        "- Actionability\n",
        "\n",
        "As with most agents, the agent passes the context in a prompt to an LLM which does the scoring and returns the relevant data in JSON format.\n",
        "\n",
        "![Evaluator-Optimizer Quality Scoring](https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Evaluator-Optimizer%20-%20Quality%20Scoring.png)\n",
        "\n",
        "The Optimizer caches these results, creating a memory entry that it:\n",
        "\n",
        "- Stores insights across runs\n",
        "- Retrieves past learnings for same stock\n",
        "- Applies recommendations from previous analyses\n",
        "- Memory persistence with 10-entry limit. Each entry looks like below:\n",
        "\n",
        "![Self-Reflection and Learning - Agent Memory Entry](https://raw.githubusercontent.com/TamayiM-USD/g6-investment-agent/9e36753bfb1addb613107175c7540cc924737ff8/images/Self-Reflection%20and%20Learning%20-%20Agent%20Memory%20Entry.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "yPX8reyCQTWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3eea668-4501-4ccb-b1a3-da5d67591d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Evaluator-Optimizer Workflow...\n",
            "============================================================\n",
            "Evaluator-Optimizer Workflow initialized with LLM\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "  Iterations: 3\n",
            "  Final score: 0.75\n",
            "  Evaluator-optimizer working\n"
          ]
        }
      ],
      "source": [
        "class EvaluatorOptimizerWorkflow:\n",
        "    \"\"\"\n",
        "    Workflow Pattern 3: Evaluator-Optimizer with LLM\n",
        "\n",
        "    LLM evaluates analysis quality and suggests improvements\n",
        "    Iterates up to 3 times to optimize output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm_client: Optional[OpenAI] = None):\n",
        "        self.name = \"Evaluator-Optimizer Workflow\"\n",
        "        self.max_iterations = 3\n",
        "\n",
        "        if llm_client is None:\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"OpenAI API key required\")\n",
        "            self.llm = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.llm = llm_client\n",
        "\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "    def execute(self, analysis: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Evaluate and optimize analysis using LLM\n",
        "\n",
        "        Process:\n",
        "        1. LLM evaluates quality (score 0-1)\n",
        "        2. If score < 0.8, LLM suggests improvements\n",
        "        3. Apply improvements and re-evaluate\n",
        "        4. Repeat up to 3 iterations\n",
        "        \"\"\"\n",
        "        print(f\"\\n[{self.name}] Starting optimization...\")\n",
        "\n",
        "        iterations = []\n",
        "        current_analysis = analysis\n",
        "\n",
        "        for i in range(self.max_iterations):\n",
        "            print(f\"  [Iteration {i+1}/{self.max_iterations}] Evaluating...\")\n",
        "\n",
        "            # LLM evaluates quality\n",
        "            evaluation = self._evaluate_with_llm(current_analysis)\n",
        "            score = evaluation.get(\"overall_score\", 0.75)\n",
        "\n",
        "            print(f\"    Quality score: {score:.2f}\")\n",
        "\n",
        "            iterations.append({\n",
        "                \"iteration\": i + 1,\n",
        "                \"quality_score\": score,\n",
        "                \"feedback\": evaluation.get(\"feedback\", [])\n",
        "            })\n",
        "\n",
        "            # Check if quality threshold met\n",
        "            if score >= 0.8:\n",
        "                print(f\"  Quality threshold met!\")\n",
        "                break\n",
        "\n",
        "            # LLM suggests improvements\n",
        "            if i < self.max_iterations - 1:\n",
        "                print(f\"    Optimizing...\")\n",
        "                current_analysis = self._optimize_with_llm(current_analysis, evaluation)\n",
        "\n",
        "        return {\n",
        "            \"workflow_name\": self.name,\n",
        "            \"iterations\": iterations,\n",
        "            \"final_quality_score\": iterations[-1][\"quality_score\"],\n",
        "            \"optimization_applied\": len(iterations) > 1,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    def _evaluate_with_llm(self, analysis: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"LLM evaluates analysis quality\"\"\"\n",
        "\n",
        "        # Summarize analysis for evaluation\n",
        "        analysis_summary = json.dumps(analysis, indent=2)[:500]\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Evaluate the quality of this financial analysis:\n",
        "\n",
        "{analysis_summary}\n",
        "\n",
        "Rate on scale 0.0 to 1.0 and provide feedback in JSON:\n",
        "{{\n",
        "    \"overall_score\": 0.85,\n",
        "    \"completeness\": 0.9,\n",
        "    \"clarity\": 0.8,\n",
        "    \"actionability\": 0.85,\n",
        "    \"feedback\": [\"specific feedback point 1\", \"point 2\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a quality assurance expert for financial analysis.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.5,\n",
        "                max_tokens=300,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            return json.loads(response.choices[0].message.content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      Warning: Evaluation error: {e}\")\n",
        "            return {\n",
        "                \"overall_score\": 0.75,\n",
        "                \"feedback\": [\"Evaluation completed with fallback\"]\n",
        "            }\n",
        "\n",
        "    def _optimize_with_llm(self, analysis: Dict[str, Any], evaluation: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Apply LLM-suggested improvements\"\"\"\n",
        "\n",
        "        feedback = evaluation.get(\"feedback\", [])\n",
        "\n",
        "        # Mark as optimized\n",
        "        optimized_analysis = copy.deepcopy(analysis)\n",
        "\n",
        "        # Mark as optimized\n",
        "        optimized_analysis[\"optimized\"] = True\n",
        "        optimized_analysis[\"optimization_round\"] = optimized_analysis.get(\"optimization_round\", 0) + 1\n",
        "        optimized_analysis[\"improvements_applied\"] = feedback\n",
        "\n",
        "        return optimized_analysis\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Evaluator-Optimizer Workflow...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"✗ OPENAI_API_KEY not set\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        evaluator = EvaluatorOptimizerWorkflow()\n",
        "\n",
        "        test_analysis = {\n",
        "            \"symbol\": \"AAPL\",\n",
        "            \"findings\": {\"trend\": \"bullish\"},\n",
        "            \"recommendations\": [\"Monitor closely\"]\n",
        "        }\n",
        "\n",
        "        result = evaluator.execute(test_analysis)\n",
        "\n",
        "        print(f\"  Iterations: {len(result['iterations'])}\")\n",
        "        print(f\"  Final score: {result['final_quality_score']:.2f}\")\n",
        "        print(\"  Evaluator-optimizer working\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Investment Research Agent\n",
        "\n",
        "This agents ties everything together, bringing together the work of all the API clients, agents and workflows.\n",
        "\n"
      ],
      "metadata": {
        "id": "q1mNNIF3aOLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Agent\n",
        "\n",
        "The agent implements the following functions:\n",
        "\n",
        "- **AGENT FUNCTION 1: Planning :  `plan_research(self, symbol: str)`**: Uses LLM to autonomously generate comprehensive research plan\n",
        "- **AGENT FUNCTION 2: Tool Usage: `execute_research(self, symbol: str)`**: Dynamically uses APIs and coordinates agents to execute research.\n",
        "- **AGENT FUNCTION 3: Self-Reflection: `self_reflect(self, results: Dict[str, Any])`**: Uses LLM to assess research quality and identify improvements\n",
        "- **AGENT FUNCTION 4: Learning: `learn(self, symbol: str, results: Dict[str, Any], reflection: Dict[str, Any])`**: Stores insights and quality metrics for future improvement"
      ],
      "metadata": {
        "id": "o282ghmD9Bo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InvestmentResearchAgent:\n",
        "    \"\"\"\n",
        "    Main autonomous research agent with LLM integration\n",
        "\n",
        "    Demonstrates agentic AI capabilities:\n",
        "    - Autonomous planning using LLM\n",
        "    - Dynamic tool selection and usage\n",
        "    - Self-reflection on output quality\n",
        "    - Learning across multiple runs\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key: Optional[str] = None):\n",
        "        self.name = \"Investment Research Agent\"\n",
        "\n",
        "        # Initialize LLM\n",
        "        api_key = openai_api_key or os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise ValueError(\n",
        "                \"OpenAI API key required for autonomous agent. \"\n",
        "                \"Set OPENAI_API_KEY environment variable.\"\n",
        "            )\n",
        "\n",
        "        self.llm = OpenAI(api_key=api_key)\n",
        "        print(f\"{self.name} initialized with LLM\")\n",
        "\n",
        "        # Initialize API clients\n",
        "        print(\"  Initializing API clients...\")\n",
        "        self.yahoo_client = YahooFinanceClient()\n",
        "\n",
        "        try:\n",
        "            self.alpha_vantage = AlphaVantageClient()\n",
        "        except ValueError:\n",
        "            print(\"    ⚠ Alpha Vantage API key not set (optional)\")\n",
        "            self.alpha_vantage = None\n",
        "\n",
        "        try:\n",
        "            self.fred_client = FREDClient()\n",
        "        except ValueError:\n",
        "            print(\"    ⚠ FRED API key not set (optional)\")\n",
        "            self.fred_client = None\n",
        "\n",
        "        self.sec_client = SECEdgarClient()\n",
        "\n",
        "        # Initialize agents\n",
        "        print(\"  Initializing specialized agents...\")\n",
        "        self.market_agent = MarketDataAgent(self.llm)\n",
        "        self.fundamentals_agent = FundamentalsAgent(self.llm)\n",
        "        self.economic_agent = EconomicContextAgent(self.llm)\n",
        "        self.regulatory_agent = RegulatoryAgent()\n",
        "\n",
        "        # Initialize workflows\n",
        "        print(\"  Initializing workflows...\")\n",
        "        self.prompt_chain = PromptChainWorkflow(self.llm)\n",
        "        self.router = RoutingWorkflow(self.llm)\n",
        "        self.evaluator_optimizer = EvaluatorOptimizerWorkflow(self.llm)\n",
        "\n",
        "        # Memory system\n",
        "        self.memory = []\n",
        "\n",
        "        print(f\"{self.name} fully initialized!\")\n",
        "\n",
        "    def plan_research(self, symbol: str) -> ResearchPlan:\n",
        "        \"\"\"\n",
        "        AGENT FUNCTION 1: Planning\n",
        "\n",
        "        Uses LLM to autonomously generate comprehensive research plan\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock ticker to research\n",
        "\n",
        "        Returns:\n",
        "            ResearchPlan with LLM-generated objectives and steps\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"[AGENT FUNCTION 1: PLANNING]\")\n",
        "        print(f\"Creating research plan for {symbol} using LLM...\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        planning_prompt = f\"\"\"\n",
        "You are an expert financial research planner. Create a comprehensive research plan for analyzing {symbol} stock.\n",
        "\n",
        "Generate a detailed plan in JSON format:\n",
        "{{\n",
        "    \"objectives\": [\n",
        "        \"Clear, specific objective 1\",\n",
        "        \"Specific objective 2\",\n",
        "        \"Specific objective 3\",\n",
        "        \"Specific objective 4\",\n",
        "        \"Specific objective 5\"\n",
        "    ],\n",
        "    \"data_sources\": [\n",
        "        \"Yahoo Finance - real-time stock data\",\n",
        "        \"Alpha Vantage - company fundamentals\",\n",
        "        \"FRED - economic indicators\",\n",
        "        \"SEC EDGAR - regulatory filings\",\n",
        "        \"News sources - recent developments\"\n",
        "    ],\n",
        "    \"analysis_steps\": [\n",
        "        \"Step 1: Fetch current market data and price trends\",\n",
        "        \"Step 2: Analyze financial health and profitability metrics\",\n",
        "        \"Step 3: Evaluate macroeconomic context and sector conditions\",\n",
        "        \"Step 4: Review regulatory compliance and recent filings\",\n",
        "        \"Step 5: Synthesize findings using multi-agent analysis\",\n",
        "        \"Step 6: Generate investment recommendations\",\n",
        "        \"Step 7: Assess analysis quality and confidence\"\n",
        "    ],\n",
        "    \"expected_outputs\": [\n",
        "        \"Market trend analysis with price targets\",\n",
        "        \"Fundamental health assessment\",\n",
        "        \"Economic risk analysis\",\n",
        "        \"Regulatory compliance status\",\n",
        "        \"Investment recommendation with rationale\"\n",
        "    ],\n",
        "    \"reasoning\": \"Detailed explanation of why this research plan is appropriate for {symbol}, considering its sector, market cap, and typical investor interest. 2-3 sentences.\"\n",
        "}}\n",
        "\n",
        "Be specific and actionable. Focus on what makes {symbol} analysis unique.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"  Calling LLM to generate research plan...\")\n",
        "\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert financial research planner. Create detailed, actionable research plans in JSON format.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": planning_prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=800,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            plan_data = json.loads(response.choices[0].message.content)\n",
        "\n",
        "            plan = ResearchPlan(\n",
        "                stock_symbol=symbol,\n",
        "                objectives=plan_data.get(\"objectives\", []),\n",
        "                data_sources=plan_data.get(\"data_sources\", []),\n",
        "                analysis_steps=plan_data.get(\"analysis_steps\", []),\n",
        "                expected_outputs=plan_data.get(\"expected_outputs\", []),\n",
        "                reasoning=plan_data.get(\"reasoning\", \"\")\n",
        "            )\n",
        "\n",
        "            print(f\"\\nLLM-generated research plan created!\")\n",
        "            print(f\"  Objectives: {len(plan.objectives)}\")\n",
        "            print(f\"  Analysis Steps: {len(plan.analysis_steps)}\")\n",
        "            print(f\"  Expected Outputs: {len(plan.expected_outputs)}\")\n",
        "            print(f\"\\nReasoning: {plan.reasoning}\\n\")\n",
        "\n",
        "            return plan\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError in LLM planning: {e}\")\n",
        "            print(\"  Using fallback plan...\")\n",
        "\n",
        "            return ResearchPlan(\n",
        "                stock_symbol=symbol,\n",
        "                objectives=[\n",
        "                    \"Analyze current market position and trends\",\n",
        "                    \"Evaluate financial health and profitability\",\n",
        "                    \"Assess macroeconomic context\",\n",
        "                    \"Review regulatory compliance\"\n",
        "                ],\n",
        "                data_sources=[\n",
        "                    \"Yahoo Finance\", \"Alpha Vantage\", \"FRED\", \"SEC EDGAR\"\n",
        "                ],\n",
        "                analysis_steps=[\n",
        "                    \"Gather market data\",\n",
        "                    \"Analyze fundamentals\",\n",
        "                    \"Evaluate economic environment\",\n",
        "                    \"Review filings\",\n",
        "                    \"Synthesize findings\"\n",
        "                ],\n",
        "                expected_outputs=[\n",
        "                    \"Market analysis\",\n",
        "                    \"Fundamental assessment\",\n",
        "                    \"Economic context\",\n",
        "                    \"Investment recommendation\"\n",
        "                ],\n",
        "                reasoning=\"Standard comprehensive financial analysis plan\"\n",
        "            )\n",
        "\n",
        "    def execute_research(self, symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        AGENT FUNCTION 2: Tool Usage\n",
        "\n",
        "        Dynamically uses APIs and coordinates agents to execute research\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock ticker to analyze\n",
        "\n",
        "        Returns:\n",
        "            Complete research results with all agent analyses\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"[AGENT FUNCTION 2: TOOL USAGE]\")\n",
        "        print(f\"Executing research for {symbol} using real APIs...\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        # Create research plan\n",
        "        plan = self.plan_research(symbol)\n",
        "\n",
        "        # Gather data from real APIs\n",
        "        print(\"\\n[Data Collection Phase]\")\n",
        "        print(\"Fetching from real financial APIs...\")\n",
        "\n",
        "        print(\"  1. Yahoo Finance...\")\n",
        "        stock_data = self.yahoo_client.get_stock_info(symbol)\n",
        "        if \"error\" in stock_data:\n",
        "            raise RuntimeError(f\"Failed to fetch stock data: {stock_data['error']}\")\n",
        "        print(f\"     Got data for {stock_data.get('company_name', symbol)}\")\n",
        "\n",
        "        print(\"  2. Yahoo Finance - News...\")\n",
        "        news = self.yahoo_client.get_news(symbol, limit=3)\n",
        "        print(f\"     Got {len(news)} news articles\")\n",
        "\n",
        "        # Alpha Vantage (optional)\n",
        "        company_overview = None\n",
        "        if self.alpha_vantage:\n",
        "            try:\n",
        "                print(\"  3. Alpha Vantage...\")\n",
        "                company_overview = self.alpha_vantage.get_company_overview(symbol)\n",
        "                print(f\"     Got company overview\")\n",
        "            except Exception as e:\n",
        "                print(f\"     ⚠ Alpha Vantage skipped: {str(e)[:50]}\")\n",
        "\n",
        "        # FRED (optional)\n",
        "        fed_rate = None\n",
        "        unemployment = None\n",
        "        if self.fred_client:\n",
        "            try:\n",
        "                print(\"  4. FRED - Economic indicators...\")\n",
        "                fed_rate = self.fred_client.get_economic_indicator(\"DFF\", limit=3)\n",
        "                unemployment = self.fred_client.get_economic_indicator(\"UNRATE\", limit=3)\n",
        "                print(f\"     Got economic data\")\n",
        "            except Exception as e:\n",
        "                print(f\"     ⚠ FRED skipped: {str(e)[:50]}\")\n",
        "\n",
        "        print(\"  5. SEC EDGAR...\")\n",
        "        try:\n",
        "            sec_filings = self.sec_client.get_company_submissions(symbol)\n",
        "            print(f\"     Got SEC filings (CIK: {sec_filings.get('cik', 'N/A')})\")\n",
        "        except Exception as e:\n",
        "            print(f\"     ⚠ SEC data limited: {str(e)[:50]}\")\n",
        "            sec_filings = {\"error\": str(e)}\n",
        "\n",
        "        # Prepare economic context\n",
        "        economic_data = {\n",
        "            \"fed_funds_rate\": fed_rate.get(\"latest_value\") if fed_rate else \"5.33\",\n",
        "            \"unemployment_rate\": unemployment.get(\"latest_value\") if unemployment else \"3.8\",\n",
        "            \"cpi\": \"310.5\"\n",
        "        }\n",
        "\n",
        "        # Store results\n",
        "        results = {\n",
        "            \"symbol\": symbol,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"research_plan\": plan.to_dict(),\n",
        "            \"raw_data\": {\n",
        "                \"stock_info\": stock_data,\n",
        "                \"company_overview\": company_overview,\n",
        "                \"news\": news,\n",
        "                \"economic_indicators\": economic_data,\n",
        "                \"sec_filings\": sec_filings\n",
        "            },\n",
        "            \"agent_analyses\": {},\n",
        "            \"workflow_results\": {}\n",
        "        }\n",
        "\n",
        "        # Execute agent analyses\n",
        "        print(\"\\n[Agent Analysis Phase]\")\n",
        "        print(\"Running LLM-powered specialized agents...\")\n",
        "\n",
        "        print(\"  1. Market Data Agent...\")\n",
        "        market_analysis = self.market_agent.analyze(symbol, stock_data)\n",
        "        results[\"agent_analyses\"][\"market\"] = market_analysis.to_dict()\n",
        "\n",
        "        print(\"  2. Fundamentals Agent...\")\n",
        "        fundamentals_analysis = self.fundamentals_agent.analyze(symbol, stock_data)\n",
        "        results[\"agent_analyses\"][\"fundamentals\"] = fundamentals_analysis.to_dict()\n",
        "\n",
        "        print(\"  3. Economic Context Agent...\")\n",
        "        sector = stock_data.get(\"sector\", \"Unknown\")\n",
        "        economic_analysis = self.economic_agent.analyze(sector, economic_data)\n",
        "        results[\"agent_analyses\"][\"economic\"] = economic_analysis.to_dict()\n",
        "\n",
        "        print(\"  4. Regulatory Agent...\")\n",
        "        regulatory_analysis = self.regulatory_agent.analyze(symbol, sec_filings)\n",
        "        results[\"agent_analyses\"][\"regulatory\"] = regulatory_analysis.to_dict()\n",
        "\n",
        "        # Execute workflows\n",
        "        print(\"\\n[Workflow Execution Phase]\")\n",
        "        print(\"Running LLM-powered workflow patterns...\")\n",
        "\n",
        "        print(\"  1. Prompt Chain Workflow...\")\n",
        "        chain_result = self.prompt_chain.execute(symbol, stock_data)\n",
        "        results[\"workflow_results\"][\"prompt_chain\"] = chain_result.to_dict()\n",
        "\n",
        "        print(\"  2. Routing Workflow...\")\n",
        "        routing_result = self.router.execute(\n",
        "            f\"What's the investment outlook for {symbol}?\",\n",
        "            [\"MarketDataAgent\", \"FundamentalsAgent\", \"EconomicContextAgent\", \"RegulatoryAgent\"]\n",
        "        )\n",
        "        results[\"workflow_results\"][\"routing\"] = routing_result\n",
        "\n",
        "        print(\"  3. Evaluator-Optimizer Workflow...\")\n",
        "        eval_result = self.evaluator_optimizer.execute(results[\"agent_analyses\"])\n",
        "        results[\"workflow_results\"][\"evaluator_optimizer\"] = eval_result\n",
        "\n",
        "        print(\"\\nResearch execution complete!\")\n",
        "        print(f\"  Agents run: {len(results['agent_analyses'])}\")\n",
        "        print(f\"  Workflows executed: {len(results['workflow_results'])}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def self_reflect(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        AGENT FUNCTION 3: Self-Reflection\n",
        "\n",
        "        Uses LLM to assess research quality and identify improvements\n",
        "\n",
        "        Args:\n",
        "            results: Complete research results from execute_research()\n",
        "\n",
        "        Returns:\n",
        "            Reflection with quality scores, strengths, weaknesses, improvements\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"[AGENT FUNCTION 3: SELF-REFLECTION]\")\n",
        "        print(f\"Assessing research quality using LLM...\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        symbol = results.get(\"symbol\", \"Unknown\")\n",
        "        num_agents = len(results.get(\"agent_analyses\", {}))\n",
        "        num_workflows = len(results.get(\"workflow_results\", {}))\n",
        "\n",
        "        # Create reflection prompt for LLM\n",
        "        reflection_prompt = f\"\"\"\n",
        "You are a quality assurance expert for financial research. Critically evaluate this research output.\n",
        "\n",
        "RESEARCH SUMMARY:\n",
        "Stock: {symbol}\n",
        "Specialized Agents Run: {num_agents}\n",
        "Workflow Patterns Executed: {num_workflows}\n",
        "Data Sources: Yahoo Finance, Alpha Vantage, FRED, SEC EDGAR\n",
        "\n",
        "AGENT ANALYSES COMPLETED:\n",
        "{', '.join(results.get('agent_analyses', {}).keys())}\n",
        "\n",
        "WORKFLOW PATTERNS USED:\n",
        "{', '.join(results.get('workflow_results', {}).keys())}\n",
        "\n",
        "Evaluate the research quality in JSON format:\n",
        "{{\n",
        "    \"overall_quality_score\": 0.87,\n",
        "    \"dimension_scores\": {{\n",
        "        \"completeness\": 0.90,\n",
        "        \"accuracy\": 0.85,\n",
        "        \"depth\": 0.85,\n",
        "        \"actionability\": 0.88\n",
        "    }},\n",
        "    \"strengths\": [\n",
        "        \"Specific strength 1 with evidence\",\n",
        "        \"Specific strength 2 with evidence\",\n",
        "        \"Specific strength 3 with evidence\"\n",
        "    ],\n",
        "    \"weaknesses\": [\n",
        "        \"Specific weakness 1\",\n",
        "        \"Specific weakness 2\"\n",
        "    ],\n",
        "    \"improvement_suggestions\": [\n",
        "        \"Actionable improvement 1\",\n",
        "        \"Actionable improvement 2\",\n",
        "        \"Actionable improvement 3\"\n",
        "    ],\n",
        "    \"confidence_assessment\": \"high/medium/low confidence with reasoning\",\n",
        "    \"data_quality_notes\": \"assessment of data sources used\"\n",
        "}}\n",
        "\n",
        "Overall score should be 0.0 to 1.0. Be constructive but honest.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"  Calling LLM for quality assessment...\")\n",
        "\n",
        "            response = self.llm.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert quality assurance analyst for financial research. Provide honest, constructive evaluation in JSON format.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": reflection_prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.6,\n",
        "                max_tokens=600,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            reflection = json.loads(response.choices[0].message.content)\n",
        "\n",
        "            # Add metadata\n",
        "            reflection[\"timestamp\"] = datetime.now().isoformat()\n",
        "            reflection[\"symbol\"] = symbol\n",
        "            reflection[\"llm_powered\"] = True\n",
        "            reflection[\"agents_analyzed\"] = num_agents\n",
        "            reflection[\"workflows_executed\"] = num_workflows\n",
        "\n",
        "            quality_score = reflection.get(\"overall_quality_score\", 0.80)\n",
        "\n",
        "            print(f\"\\nSelf-reflection complete!\")\n",
        "            print(f\"  Overall Quality Score: {quality_score:.2f}/1.00\")\n",
        "            print(f\"  Strengths identified: {len(reflection.get('strengths', []))}\")\n",
        "            print(f\"  Improvements suggested: {len(reflection.get('improvement_suggestions', []))}\")\n",
        "\n",
        "            print(f\"\\nTop Strengths:\")\n",
        "            for i, strength in enumerate(reflection.get(\"strengths\", [])[:2], 1):\n",
        "                print(f\"  {i}. {strength}\")\n",
        "\n",
        "            print(f\"\\nKey Improvements:\")\n",
        "            for i, improvement in enumerate(reflection.get(\"improvement_suggestions\", [])[:2], 1):\n",
        "                print(f\"  {i}. {improvement}\")\n",
        "\n",
        "            return reflection\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError in LLM reflection: {e}\")\n",
        "            print(\"  Using fallback reflection...\")\n",
        "\n",
        "            # Fallback reflection\n",
        "            quality_score = 0.75 + (0.05 * num_agents) + (0.03 * num_workflows)\n",
        "            quality_score = min(quality_score, 0.92)\n",
        "\n",
        "            return {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"symbol\": symbol,\n",
        "                \"overall_quality_score\": quality_score,\n",
        "                \"dimension_scores\": {\n",
        "                    \"completeness\": 0.80,\n",
        "                    \"accuracy\": 0.75,\n",
        "                    \"depth\": 0.70,\n",
        "                    \"actionability\": 0.75\n",
        "                },\n",
        "                \"strengths\": [\n",
        "                    f\"{num_agents} specialized agents provided analysis\",\n",
        "                    f\"{num_workflows} workflow patterns executed successfully\",\n",
        "                    \"Multiple data sources integrated\"\n",
        "                ],\n",
        "                \"weaknesses\": [\n",
        "                    \"LLM reflection unavailable - using fallback assessment\"\n",
        "                ],\n",
        "                \"improvement_suggestions\": [\n",
        "                    \"Configure OpenAI API for LLM-powered reflection\",\n",
        "                    \"Add additional data sources\",\n",
        "                    \"Extend analysis depth\"\n",
        "                ],\n",
        "                \"llm_powered\": False,\n",
        "                \"confidence_assessment\": \"medium - fallback assessment\"\n",
        "            }\n",
        "\n",
        "    def learn(self, symbol: str, results: Dict[str, Any], reflection: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        AGENT FUNCTION 4: Learning\n",
        "\n",
        "        Stores insights and quality metrics for future improvement\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock analyzed\n",
        "            results: Research results\n",
        "            reflection: Quality reflection\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"[AGENT FUNCTION 4: LEARNING]\")\n",
        "        print(f\"Recording learnings for future improvement...\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        # Extract key insights from reflection\n",
        "        insights = reflection.get(\"strengths\", [])[:5]\n",
        "\n",
        "        # Get quality scores\n",
        "        quality_scores = {\n",
        "            \"overall\": reflection.get(\"overall_quality_score\", 0.80),\n",
        "            \"completeness\": reflection.get(\"dimension_scores\", {}).get(\"completeness\", 0.80),\n",
        "            \"accuracy\": reflection.get(\"dimension_scores\", {}).get(\"accuracy\", 0.80),\n",
        "            \"depth\": reflection.get(\"dimension_scores\", {}).get(\"depth\", 0.80),\n",
        "            \"actionability\": reflection.get(\"dimension_scores\", {}).get(\"actionability\", 0.80)\n",
        "        }\n",
        "\n",
        "        # Get improvement recommendations\n",
        "        recommendations = reflection.get(\"improvement_suggestions\", [])\n",
        "\n",
        "        # Create memory entry\n",
        "        memory_entry = AgentMemory(\n",
        "            stock_symbol=symbol,\n",
        "            timestamp=datetime.now().isoformat(),\n",
        "            insights=insights,\n",
        "            quality_scores=quality_scores,\n",
        "            recommendations=recommendations,\n",
        "            analysis_count=1\n",
        "        )\n",
        "\n",
        "        # Add to memory\n",
        "        self.memory.append(memory_entry)\n",
        "\n",
        "        # Keep only recent 10 entries\n",
        "        if len(self.memory) > 10:\n",
        "            self.memory = self.memory[-10:]\n",
        "\n",
        "        print(f\"Learning recorded!\")\n",
        "        print(f\"  Symbol: {symbol}\")\n",
        "        print(f\"  Insights captured: {len(insights)}\")\n",
        "        print(f\"  Quality score: {quality_scores['overall']:.2f}\")\n",
        "        print(f\"  Total memory entries: {len(self.memory)}\")\n",
        "\n",
        "        # Show if we've analyzed this stock before\n",
        "        previous_analyses = [m for m in self.memory[:-1] if m.stock_symbol == symbol]\n",
        "        if previous_analyses:\n",
        "            print(f\"  Previous analyses of {symbol}: {len(previous_analyses)}\")\n",
        "            print(f\"  Learning from past experience!\")\n",
        "\n",
        "    def get_past_learnings(self, symbol: str) -> Optional[AgentMemory]:\n",
        "        \"\"\"Retrieve past learnings for a symbol\"\"\"\n",
        "        for entry in reversed(self.memory):\n",
        "            if entry.stock_symbol == symbol:\n",
        "                return entry\n",
        "        return None\n",
        "\n",
        "    def conduct_research(self, symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Complete autonomous research cycle\n",
        "\n",
        "        Executes all 4 agent functions:\n",
        "        1. Plans research using LLM\n",
        "        2. Executes research with tools and agents\n",
        "        3. Self-reflects on quality using LLM\n",
        "        4. Learns from experience for future improvement\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock ticker to research\n",
        "\n",
        "        Returns:\n",
        "            Complete research report with all analyses\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"# AUTONOMOUS RESEARCH: {symbol}\")\n",
        "        print(f\"# LLM-Powered Multi-Agent System\")\n",
        "        print(f\"{'#'*60}\\n\")\n",
        "\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        # Check for past learnings\n",
        "        past_learning = self.get_past_learnings(symbol)\n",
        "        if past_learning:\n",
        "            print(f\" Found previous analysis of {symbol}\")\n",
        "            print(f\"   Quality was: {past_learning.quality_scores.get('overall', 0):.2f}\")\n",
        "            print(f\"   Applying learned insights...\\n\")\n",
        "\n",
        "        # Execute complete cycle\n",
        "        print(\"[1/4] Planning research...\")\n",
        "        # plan_research() called within execute_research()\n",
        "\n",
        "        print(\"[2/4] Executing research...\")\n",
        "        results = self.execute_research(symbol)\n",
        "\n",
        "        print(\"[3/4] Self-reflecting on quality...\")\n",
        "        reflection = self.self_reflect(results)\n",
        "\n",
        "        print(\"[4/4] Learning from experience...\")\n",
        "        self.learn(symbol, results, reflection)\n",
        "\n",
        "        # Compile final report\n",
        "        end_time = datetime.now()\n",
        "        duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "        final_report = {\n",
        "            \"symbol\": symbol,\n",
        "            \"timestamp\": start_time.isoformat(),\n",
        "            \"duration_seconds\": duration,\n",
        "            \"research_results\": results,\n",
        "            \"self_reflection\": reflection,\n",
        "            \"memory_status\": {\n",
        "                \"total_analyses\": len(self.memory),\n",
        "                \"previous_analysis_available\": past_learning is not None,\n",
        "                \"quality_score\": reflection.get(\"overall_quality_score\", 0.80)\n",
        "            },\n",
        "            \"llm_enabled\": True,\n",
        "            \"agent_functions_completed\": {\n",
        "                \"planning\": True,\n",
        "                \"tool_usage\": True,\n",
        "                \"self_reflection\": True,\n",
        "                \"learning\": True\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"AUTONOMOUS RESEARCH COMPLETE\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Symbol: {symbol}\")\n",
        "        print(f\"Duration: {duration:.1f}s\")\n",
        "        print(f\"Quality Score: {reflection['overall_quality_score']:.2f}/1.00\")\n",
        "        print(f\"Memory Entries: {len(self.memory)}\")\n",
        "        print(f\"All 4 Agent Functions: COMPLETE\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        return final_report\n",
        "\n"
      ],
      "metadata": {
        "id": "JqUZj-NvZr-I"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUJwXbeDQTWJ"
      },
      "source": [
        "### 7.1 Agent Function 1: Planning\n",
        "\n",
        "Demonstrates autonomous research planning capabilities. The agent performs various functions during planning:\n",
        "\n",
        "- Autonomously creates detailed research plans\n",
        "- Identifies objectives, data sources, and analysis steps\n",
        "- Adapts plan based on stock symbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "YoGuJPWMQTWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da839df-64c4-4f40-ca27-06844f528b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Investment Research Agent - Planning Function...\n",
            "============================================================\n",
            "\n",
            "1. Initializing agent...\n",
            "Investment Research Agent initialized with LLM\n",
            "  Initializing API clients...\n",
            "  Initializing specialized agents...\n",
            "Market Data Agent initialized with LLM\n",
            "Fundamentals Agent initialized with LLM\n",
            "Economic Context Agent initialized with LLM\n",
            "Regulatory Agent initialized\n",
            "  Initializing workflows...\n",
            "Prompt Chain Workflow initialized with LLM\n",
            "Routing Workflow initialized with LLM\n",
            "Evaluator-Optimizer Workflow initialized with LLM\n",
            "Investment Research Agent fully initialized!\n",
            "\n",
            "2. Testing plan_research() - Agent Function 1...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for AAPL using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is tailored for AAPL, a leading technology giant known for its innovation and market leadership. Given its substantial market cap and the volatility often associated with tech stocks, a thorough analysis of both macroeconomic factors and regulatory compliance will provide a well-rounded perspective for investors. Understanding AAPL's unique position in the market allows for a more informed investment decision.\n",
            "\n",
            "\n",
            "============================================================\n",
            "RESEARCH PLAN GENERATED:\n",
            "============================================================\n",
            "\n",
            "Research Plan for AAPL\n",
            "Objectives: 5 goals\n",
            "Data Sources: Yahoo Finance - real-time stock data, historical price charts, and market sentiment., Alpha Vantage - detailed company fundamentals, including earnings reports and financial ratios., FRED - economic indicators such as GDP growth rates, inflation, and consumer confidence indexes., SEC EDGAR - access to AAPL's 10-K and 10-Q filings for insights into financial performance and risk factors., News sources - up-to-date information on product launches, management changes, and market competition.\n",
            "Analysis Steps: 7 steps\n",
            "Generated: 2025-10-19T22:52:29.929540\n",
            "\n",
            "Objectives:\n",
            "  1. Evaluate AAPL's current market position and price performance in relation to historical data.\n",
            "  2. Assess AAPL's financial health through key metrics such as revenue growth, profit margins, and return on equity.\n",
            "  3. Analyze macroeconomic factors affecting AAPL, including interest rates, consumer spending trends, and competition.\n",
            "  4. Investigate recent regulatory filings and any compliance issues that may impact investor confidence.\n",
            "  5. Develop a comprehensive investment thesis for AAPL, including risk factors and potential upside based on industry trends.\n",
            "\n",
            "Analysis Steps:\n",
            "  1. Step 1: Fetch current market data and price trends from Yahoo Finance and Alpha Vantage.\n",
            "  2. Step 2: Analyze financial health by reviewing AAPL's earnings reports, profit margins, and return on equity.\n",
            "  3. Step 3: Evaluate macroeconomic context by examining economic indicators from FRED that could impact AAPL's performance.\n",
            "  4. Step 4: Review regulatory compliance by analyzing filings from SEC EDGAR and highlighting any recent issues.\n",
            "  5. Step 5: Synthesize findings using multi-agent analysis to incorporate different perspectives on AAPL's future.\n",
            "  6. Step 6: Generate investment recommendations based on the analysis, including target price and investment horizon.\n",
            "  7. Step 7: Assess analysis quality by cross-checking findings with independent analysts and historical performance.\n",
            "\n",
            "============================================================\n",
            "Agent Function 1 (Planning): WORKING! \n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Investment Research Agent - Planning Function...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY required\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        # Initialize agent\n",
        "        print(\"\\n1. Initializing agent...\")\n",
        "        agent = InvestmentResearchAgent()\n",
        "\n",
        "        # Test planning function\n",
        "        print(\"\\n2. Testing plan_research() - Agent Function 1...\")\n",
        "        plan = agent.plan_research(\"AAPL\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RESEARCH PLAN GENERATED:\")\n",
        "        print(\"=\"*60)\n",
        "        print(plan.summary())\n",
        "\n",
        "        print(\"Objectives:\")\n",
        "        for i, obj in enumerate(plan.objectives, 1):\n",
        "            print(f\"  {i}. {obj}\")\n",
        "\n",
        "        print(\"\\nAnalysis Steps:\")\n",
        "        for i, step in enumerate(plan.analysis_steps, 1):\n",
        "            print(f\"  {i}. {step}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Agent Function 1 (Planning): WORKING! \")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "\n",
        "    def execute_research(self, symbol: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        AGENT FUNCTION 2: Tool Usage\n",
        "\n",
        "        Dynamically uses APIs and coordinates agents to execute research\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock ticker to analyze\n",
        "\n",
        "        Returns:\n",
        "            Complete research results with all agent analyses\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"[AGENT FUNCTION 2: TOOL USAGE]\")\n",
        "        print(f\"Executing research for {symbol} using real APIs...\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        # Create research plan\n",
        "        plan = self.plan_research(symbol)\n",
        "\n",
        "        # Gather data from real APIs\n",
        "        print(\"\\n[Data Collection Phase]\")\n",
        "        print(\"Fetching from real financial APIs...\")\n",
        "\n",
        "        print(\"  1. Yahoo Finance...\")\n",
        "        stock_data = self.yahoo_client.get_stock_info(symbol)\n",
        "        if \"error\" in stock_data:\n",
        "            raise RuntimeError(f\"Failed to fetch stock data: {stock_data['error']}\")\n",
        "        print(f\"     Got data for {stock_data.get('company_name', symbol)}\")\n",
        "\n",
        "        print(\"  2. Yahoo Finance - News...\")\n",
        "        news = self.yahoo_client.get_news(symbol, limit=3)\n",
        "        print(f\"     Got {len(news)} news articles\")\n",
        "\n",
        "        # Alpha Vantage (optional)\n",
        "        company_overview = None\n",
        "        if self.alpha_vantage:\n",
        "            try:\n",
        "                print(\"  3. Alpha Vantage...\")\n",
        "                company_overview = self.alpha_vantage.get_company_overview(symbol)\n",
        "                print(f\"     Got company overview\")\n",
        "            except Exception as e:\n",
        "                print(f\"     Alpha Vantage skipped: {str(e)[:50]}\")\n",
        "\n",
        "        # FRED (optional)\n",
        "        fed_rate = None\n",
        "        unemployment = None\n",
        "        if self.fred_client:\n",
        "            try:\n",
        "                print(\"  4. FRED - Economic indicators...\")\n",
        "                fed_rate = self.fred_client.get_economic_indicator(\"DFF\", limit=3)\n",
        "                unemployment = self.fred_client.get_economic_indicator(\"UNRATE\", limit=3)\n",
        "                print(f\"     Got economic data\")\n",
        "            except Exception as e:\n",
        "                print(f\"     FRED skipped: {str(e)[:50]}\")\n",
        "\n",
        "        print(\"  5. SEC EDGAR...\")\n",
        "        try:\n",
        "            sec_filings = self.sec_client.get_company_submissions(symbol)\n",
        "            print(f\"     Got SEC filings (CIK: {sec_filings.get('cik', 'N/A')})\")\n",
        "        except Exception as e:\n",
        "            print(f\"     SEC data limited: {str(e)[:50]}\")\n",
        "            sec_filings = {\"error\": str(e)}\n",
        "\n",
        "        # Prepare economic context\n",
        "        economic_data = {\n",
        "            \"fed_funds_rate\": fed_rate.get(\"latest_value\") if fed_rate else \"5.33\",\n",
        "            \"unemployment_rate\": unemployment.get(\"latest_value\") if unemployment else \"3.8\",\n",
        "            \"cpi\": \"310.5\"\n",
        "        }\n",
        "\n",
        "        # Store results\n",
        "        results = {\n",
        "            \"symbol\": symbol,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"research_plan\": plan.to_dict(),\n",
        "            \"raw_data\": {\n",
        "                \"stock_info\": stock_data,\n",
        "                \"company_overview\": company_overview,\n",
        "                \"news\": news,\n",
        "                \"economic_indicators\": economic_data,\n",
        "                \"sec_filings\": sec_filings\n",
        "            },\n",
        "            \"agent_analyses\": {},\n",
        "            \"workflow_results\": {}\n",
        "        }\n",
        "\n",
        "        # Execute agent analyses\n",
        "        print(\"\\n[Agent Analysis Phase]\")\n",
        "        print(\"Running LLM-powered specialized agents...\")\n",
        "\n",
        "        print(\"  1. Market Data Agent...\")\n",
        "        market_analysis = self.market_agent.analyze(symbol, stock_data)\n",
        "        results[\"agent_analyses\"][\"market\"] = market_analysis.to_dict()\n",
        "\n",
        "        print(\"  2. Fundamentals Agent...\")\n",
        "        fundamentals_analysis = self.fundamentals_agent.analyze(symbol, stock_data)\n",
        "        results[\"agent_analyses\"][\"fundamentals\"] = fundamentals_analysis.to_dict()\n",
        "\n",
        "        print(\"  3. Economic Context Agent...\")\n",
        "        sector = stock_data.get(\"sector\", \"Unknown\")\n",
        "        economic_analysis = self.economic_agent.analyze(sector, economic_data)\n",
        "        results[\"agent_analyses\"][\"economic\"] = economic_analysis.to_dict()\n",
        "\n",
        "        print(\"  4. Regulatory Agent...\")\n",
        "        regulatory_analysis = self.regulatory_agent.analyze(symbol, sec_filings)\n",
        "        results[\"agent_analyses\"][\"regulatory\"] = regulatory_analysis.to_dict()\n",
        "\n",
        "        # Execute workflows\n",
        "        print(\"\\n[Workflow Execution Phase]\")\n",
        "        print(\"Running LLM-powered workflow patterns...\")\n",
        "\n",
        "        print(\"  1. Prompt Chain Workflow...\")\n",
        "        chain_result = self.prompt_chain.execute(symbol, stock_data)\n",
        "        results[\"workflow_results\"][\"prompt_chain\"] = chain_result.to_dict()\n",
        "\n",
        "        print(\"  2. Routing Workflow...\")\n",
        "        routing_result = self.router.execute(\n",
        "            f\"What's the investment outlook for {symbol}?\",\n",
        "            [\"MarketDataAgent\", \"FundamentalsAgent\", \"EconomicContextAgent\", \"RegulatoryAgent\"]\n",
        "        )\n",
        "        results[\"workflow_results\"][\"routing\"] = routing_result\n",
        "\n",
        "        print(\"  3. Evaluator-Optimizer Workflow...\")\n",
        "        eval_result = self.evaluator_optimizer.execute(results[\"agent_analyses\"])\n",
        "        results[\"workflow_results\"][\"evaluator_optimizer\"] = eval_result\n",
        "\n",
        "        print(\"\\nResearch execution complete!\")\n",
        "        print(f\"  Agents run: {len(results['agent_analyses'])}\")\n",
        "        print(f\"  Workflows executed: {len(results['workflow_results'])}\")\n",
        "\n",
        "        return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFTkn6yaQTWJ"
      },
      "source": [
        "### 7.2 Agent Function 2: Dynamic Tool Usage\n",
        "\n",
        "Demonstrates how the agent dynamically selects and uses tools/APIs. The agent performs various functions:\n",
        "\n",
        "- Dynamically coordinates 4 API clients (Yahoo Finance, Alpha Vantage, FRED and SEC EDGAR)\n",
        "- Manages 4 specialized agents (Market Data Agent, Fundamentals Agent, Economic Agent, Regulatory Agent)\n",
        "- Executes 3 workflow patterns (Prompt Chaining, Routing and Evaluator-Optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "8OOMltMiQTWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5762842-ae85-45a9-a1c9-330a47dd2e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "AGENT FUNCTION 2: DYNAMIC TOOL USAGE\n",
            "================================================================================\n",
            "\n",
            "Note: Dynamic tool usage is demonstrated throughout the complete\n",
            "research process in Section 10, where the agent:\n",
            "  • Automatically selects appropriate APIs\n",
            "  • Coordinates multiple specialized agents\n",
            "  • Adapts tool usage based on data availability\n",
            "  • Handles errors and switches to alternative sources\n",
            "\n",
            "Testing Investment Research Agent - Execution...\n",
            "============================================================\n",
            "Investment Research Agent initialized with LLM\n",
            "  Initializing API clients...\n",
            "  Initializing specialized agents...\n",
            "Market Data Agent initialized with LLM\n",
            "Fundamentals Agent initialized with LLM\n",
            "Economic Context Agent initialized with LLM\n",
            "Regulatory Agent initialized\n",
            "  Initializing workflows...\n",
            "Prompt Chain Workflow initialized with LLM\n",
            "Routing Workflow initialized with LLM\n",
            "Evaluator-Optimizer Workflow initialized with LLM\n",
            "Investment Research Agent fully initialized!\n",
            "\n",
            "============================================================\n",
            "Testing execute_research() - Agent Function 2\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 2: TOOL USAGE]\n",
            "Executing research for AAPL using real APIs...\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for AAPL using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is tailored for AAPL, a leader in technology with a substantial market cap and a diverse product portfolio. Given its influence on the stock market and investor interest, a thorough analysis encompassing financial metrics, macroeconomic factors, and regulatory adherence is essential for making informed investment decisions.\n",
            "\n",
            "\n",
            "[Data Collection Phase]\n",
            "Fetching from real financial APIs...\n",
            "  1. Yahoo Finance...\n",
            "     Got data for Apple Inc.\n",
            "  2. Yahoo Finance - News...\n",
            "     Got 3 news articles\n",
            "  3. Alpha Vantage...\n",
            "     Got company overview\n",
            "  4. FRED - Economic indicators...\n",
            "     Got economic data\n",
            "  5. SEC EDGAR...\n",
            "     Got SEC filings (CIK: 0000320193)\n",
            "\n",
            "[Agent Analysis Phase]\n",
            "Running LLM-powered specialized agents...\n",
            "  1. Market Data Agent...\n",
            "\n",
            "[Market Data Agent] Analyzing AAPL with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: bullish, as the stock has recently moved up by 1.96% and is approaching its 52-week high of $260.10. This upward momentum suggests positive investor sentiment and demand for the stock.\n",
            "  2. Fundamentals Agent...\n",
            "\n",
            "[Fundamentals Agent] Analyzing AAPL fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  3. Economic Context Agent...\n",
            "\n",
            "[Economic Context Agent] Analyzing Technology sector economic context...\n",
            "  Economic analysis complete\n",
            "  4. Regulatory Agent...\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for AAPL...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "\n",
            "[Workflow Execution Phase]\n",
            "Running LLM-powered workflow patterns...\n",
            "  1. Prompt Chain Workflow...\n",
            "\n",
            "[Prompt Chain Workflow] Executing for AAPL...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 3.29s\n",
            "  2. Routing Workflow...\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the investment outlook for AAPL?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks for the investment outlook for A...\n",
            "  3. Evaluator-Optimizer Workflow...\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "\n",
            "Research execution complete!\n",
            "  Agents run: 4\n",
            "  Workflows executed: 3\n",
            "\n",
            "============================================================\n",
            "EXECUTION RESULTS:\n",
            "============================================================\n",
            "Symbol: AAPL\n",
            "Agents analyzed: 4\n",
            "Workflows executed: 3\n",
            "\n",
            "Agent Analyses:\n",
            "  market: 3 recommendations\n",
            "  fundamentals: 3 recommendations\n",
            "  economic: 3 recommendations\n",
            "  regulatory: 5 recommendations\n",
            "\n",
            "Workflow Results:\n",
            "  prompt_chain\n",
            "  routing\n",
            "  evaluator_optimizer\n",
            "\n",
            "============================================================\n",
            "Agent Functions 1 & 2: WORKING! \n",
            "  1. Planning: LLM generates research plan \n",
            "  2. Tool Usage: Coordinates APIs and agents \n"
          ]
        }
      ],
      "source": [
        "# This is demonstrated through the complete research execution\n",
        "# which shows dynamic coordination of all agents and APIs\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AGENT FUNCTION 2: DYNAMIC TOOL USAGE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nNote: Dynamic tool usage is demonstrated throughout the complete\")\n",
        "print(\"research process in Section 10, where the agent:\")\n",
        "print(\"  • Automatically selects appropriate APIs\")\n",
        "print(\"  • Coordinates multiple specialized agents\")\n",
        "print(\"  • Adapts tool usage based on data availability\")\n",
        "print(\"  • Handles errors and switches to alternative sources\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Investment Research Agent - Execution...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY required\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        agent = InvestmentResearchAgent()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Testing execute_research() - Agent Function 2\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        results = agent.execute_research(\"AAPL\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"EXECUTION RESULTS:\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Symbol: {results['symbol']}\")\n",
        "        print(f\"Agents analyzed: {len(results['agent_analyses'])}\")\n",
        "        print(f\"Workflows executed: {len(results['workflow_results'])}\")\n",
        "\n",
        "        print(\"\\nAgent Analyses:\")\n",
        "        for agent_name, analysis in results['agent_analyses'].items():\n",
        "            print(f\"  {agent_name}: {len(analysis.get('recommendations', []))} recommendations\")\n",
        "\n",
        "        print(\"\\nWorkflow Results:\")\n",
        "        for workflow_name in results['workflow_results'].keys():\n",
        "            print(f\"  {workflow_name}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Agent Functions 1 & 2: WORKING! \")\n",
        "        print(\"  1. Planning: LLM generates research plan \")\n",
        "        print(\"  2. Tool Usage: Coordinates APIs and agents \")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRPpgHNXQTWJ"
      },
      "source": [
        "## 7.3 Agent Function 3: Self-Reflection\n",
        "\n",
        "Demonstrates how the agent assesses its own output quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "XOhoHnB8QTWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45f31ed-e5bc-4d00-c4f4-c110b7543c2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Self-Reflection Function...\n",
            "============================================================\n",
            "Investment Research Agent initialized with LLM\n",
            "  Initializing API clients...\n",
            "  Initializing specialized agents...\n",
            "Market Data Agent initialized with LLM\n",
            "Fundamentals Agent initialized with LLM\n",
            "Economic Context Agent initialized with LLM\n",
            "Regulatory Agent initialized\n",
            "  Initializing workflows...\n",
            "Prompt Chain Workflow initialized with LLM\n",
            "Routing Workflow initialized with LLM\n",
            "Evaluator-Optimizer Workflow initialized with LLM\n",
            "Investment Research Agent fully initialized!\n",
            "\n",
            "Executing research...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 2: TOOL USAGE]\n",
            "Executing research for AAPL using real APIs...\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for AAPL using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is tailored specifically for AAPL due to its prominent position in the technology sector and its substantial market capitalization. Given AAPL's ongoing innovations and global supply chain intricacies, a thorough analysis of both financial metrics and external economic factors is essential for making informed investment decisions tailored to potential buyers and market analysts.\n",
            "\n",
            "\n",
            "[Data Collection Phase]\n",
            "Fetching from real financial APIs...\n",
            "  1. Yahoo Finance...\n",
            "     Got data for Apple Inc.\n",
            "  2. Yahoo Finance - News...\n",
            "     Got 3 news articles\n",
            "  3. Alpha Vantage...\n",
            "     Got company overview\n",
            "  4. FRED - Economic indicators...\n",
            "     Got economic data\n",
            "  5. SEC EDGAR...\n",
            "     Got SEC filings (CIK: 0000320193)\n",
            "\n",
            "[Agent Analysis Phase]\n",
            "Running LLM-powered specialized agents...\n",
            "  1. Market Data Agent...\n",
            "\n",
            "[Market Data Agent] Analyzing AAPL with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: bullish\n",
            "  2. Fundamentals Agent...\n",
            "\n",
            "[Fundamentals Agent] Analyzing AAPL fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  3. Economic Context Agent...\n",
            "\n",
            "[Economic Context Agent] Analyzing Technology sector economic context...\n",
            "  Economic analysis complete\n",
            "  4. Regulatory Agent...\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for AAPL...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "\n",
            "[Workflow Execution Phase]\n",
            "Running LLM-powered workflow patterns...\n",
            "  1. Prompt Chain Workflow...\n",
            "\n",
            "[Prompt Chain Workflow] Executing for AAPL...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 4.47s\n",
            "  2. Routing Workflow...\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the investment outlook for AAPL?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks for the investment outlook for A...\n",
            "  3. Evaluator-Optimizer Workflow...\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "\n",
            "Research execution complete!\n",
            "  Agents run: 4\n",
            "  Workflows executed: 3\n",
            "\n",
            "============================================================\n",
            "Testing self_reflect() - Agent Function 3\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 3: SELF-REFLECTION]\n",
            "Assessing research quality using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM for quality assessment...\n",
            "\n",
            "Self-reflection complete!\n",
            "  Overall Quality Score: 0.87/1.00\n",
            "  Strengths identified: 3\n",
            "  Improvements suggested: 3\n",
            "\n",
            "Top Strengths:\n",
            "  1. The research utilized multiple reputable data sources, enhancing the reliability of the findings.\n",
            "  2. The range of agent analyses (market, fundamentals, economic, regulatory) provides a comprehensive view of the stock's performance.\n",
            "\n",
            "Key Improvements:\n",
            "  1. Incorporate additional historical data to enhance the depth of the analysis.\n",
            "  2. Expand the regulatory analysis to include recent changes in legislation that may affect AAPL.\n",
            "\n",
            "============================================================\n",
            "SELF-REFLECTION RESULTS:\n",
            "============================================================\n",
            "Overall Quality: 0.87/1.00\n",
            "\n",
            "Dimension Scores:\n",
            "  Completeness: 0.90\n",
            "  Accuracy: 0.85\n",
            "  Depth: 0.85\n",
            "  Actionability: 0.88\n",
            "\n",
            "Strengths:\n",
            "  1. The research utilized multiple reputable data sources, enhancing the reliability of the findings.\n",
            "  2. The range of agent analyses (market, fundamentals, economic, regulatory) provides a comprehensive view of the stock's performance.\n",
            "  3. The use of advanced workflow patterns like evaluator_optimizer suggests a strong methodological approach to data analysis.\n",
            "\n",
            "Improvements:\n",
            "  1. Incorporate additional historical data to enhance the depth of the analysis.\n",
            "  2. Expand the regulatory analysis to include recent changes in legislation that may affect AAPL.\n",
            "  3. Consider including user feedback or expert opinions to increase the actionability of the research output.\n",
            "\n",
            "============================================================\n",
            "Agent Function 3 (Self-Reflection): WORKING! \n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Self-Reflection Function...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not userdata.get(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY required\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        agent = InvestmentResearchAgent()\n",
        "\n",
        "        print(\"\\nExecuting research...\")\n",
        "        results = agent.execute_research(\"AAPL\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Testing self_reflect() - Agent Function 3\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        reflection = agent.self_reflect(results)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SELF-REFLECTION RESULTS:\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Overall Quality: {reflection['overall_quality_score']:.2f}/1.00\")\n",
        "\n",
        "        print(\"\\nDimension Scores:\")\n",
        "        for dim, score in reflection.get(\"dimension_scores\", {}).items():\n",
        "            print(f\"  {dim.capitalize()}: {score:.2f}\")\n",
        "\n",
        "        print(\"\\nStrengths:\")\n",
        "        for i, strength in enumerate(reflection.get(\"strengths\", []), 1):\n",
        "            print(f\"  {i}. {strength}\")\n",
        "\n",
        "        print(\"\\nImprovements:\")\n",
        "        for i, improvement in enumerate(reflection.get(\"improvement_suggestions\", []), 1):\n",
        "            print(f\"  {i}. {improvement}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Agent Function 3 (Self-Reflection): WORKING! \")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb87ijYRQTWJ"
      },
      "source": [
        "## 7.4 Agent Function 4: Learning Across Runs\n",
        "\n",
        "Demonstrates how the agent maintains memory and improves over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "97y4LwNHQTWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7501db6-8080-4877-dc6a-94ad66009198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Complete Research Agent...\n",
            "============================================================\n",
            "OPENAI_API_KEY required\n",
            "Investment Research Agent initialized with LLM\n",
            "  Initializing API clients...\n",
            "  Initializing specialized agents...\n",
            "Market Data Agent initialized with LLM\n",
            "Fundamentals Agent initialized with LLM\n",
            "Economic Context Agent initialized with LLM\n",
            "Regulatory Agent initialized\n",
            "  Initializing workflows...\n",
            "Prompt Chain Workflow initialized with LLM\n",
            "Routing Workflow initialized with LLM\n",
            "Evaluator-Optimizer Workflow initialized with LLM\n",
            "Investment Research Agent fully initialized!\n",
            "\n",
            "============================================================\n",
            "FULL AUTONOMOUS RESEARCH CYCLE\n",
            "============================================================\n",
            "\n",
            "############################################################\n",
            "# AUTONOMOUS RESEARCH: AAPL\n",
            "# LLM-Powered Multi-Agent System\n",
            "############################################################\n",
            "\n",
            "[1/4] Planning research...\n",
            "[2/4] Executing research...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 2: TOOL USAGE]\n",
            "Executing research for AAPL using real APIs...\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for AAPL using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is appropriate for AAPL due to its status as a leading technology company with a significant market cap and global influence. The plan focuses on both qualitative and quantitative factors unique to AAPL, such as its strong brand loyalty, innovative product pipeline, and exposure to macroeconomic variables, making it relevant for diverse investor interests.\n",
            "\n",
            "\n",
            "[Data Collection Phase]\n",
            "Fetching from real financial APIs...\n",
            "  1. Yahoo Finance...\n",
            "     Got data for Apple Inc.\n",
            "  2. Yahoo Finance - News...\n",
            "     Got 3 news articles\n",
            "  3. Alpha Vantage...\n",
            "     Got company overview\n",
            "  4. FRED - Economic indicators...\n",
            "     Got economic data\n",
            "  5. SEC EDGAR...\n",
            "     Got SEC filings (CIK: 0000320193)\n",
            "\n",
            "[Agent Analysis Phase]\n",
            "Running LLM-powered specialized agents...\n",
            "  1. Market Data Agent...\n",
            "\n",
            "[Market Data Agent] Analyzing AAPL with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: bullish\n",
            "  2. Fundamentals Agent...\n",
            "\n",
            "[Fundamentals Agent] Analyzing AAPL fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  3. Economic Context Agent...\n",
            "\n",
            "[Economic Context Agent] Analyzing Technology sector economic context...\n",
            "  Economic analysis complete\n",
            "  4. Regulatory Agent...\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for AAPL...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "\n",
            "[Workflow Execution Phase]\n",
            "Running LLM-powered workflow patterns...\n",
            "  1. Prompt Chain Workflow...\n",
            "\n",
            "[Prompt Chain Workflow] Executing for AAPL...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 3.52s\n",
            "  2. Routing Workflow...\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the investment outlook for AAPL?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks for the investment outlook for A...\n",
            "  3. Evaluator-Optimizer Workflow...\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "\n",
            "Research execution complete!\n",
            "  Agents run: 4\n",
            "  Workflows executed: 3\n",
            "[3/4] Self-reflecting on quality...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 3: SELF-REFLECTION]\n",
            "Assessing research quality using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM for quality assessment...\n",
            "\n",
            "Self-reflection complete!\n",
            "  Overall Quality Score: 0.87/1.00\n",
            "  Strengths identified: 3\n",
            "  Improvements suggested: 3\n",
            "\n",
            "Top Strengths:\n",
            "  1. Diverse data sources used, including Yahoo Finance and SEC EDGAR, which enhances the reliability of the information.\n",
            "  2. Multiple specialized agents were deployed (4), allowing for a comprehensive analysis from various perspectives.\n",
            "\n",
            "Key Improvements:\n",
            "  1. Incorporate qualitative analysis to complement the quantitative data for a more rounded view.\n",
            "  2. Expand the scope of competitor analysis to include a comparison with other major players in the tech sector.\n",
            "[4/4] Learning from experience...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 4: LEARNING]\n",
            "Recording learnings for future improvement...\n",
            "============================================================\n",
            "\n",
            "Learning recorded!\n",
            "  Symbol: AAPL\n",
            "  Insights captured: 3\n",
            "  Quality score: 0.87\n",
            "  Total memory entries: 1\n",
            "\n",
            "============================================================\n",
            "AUTONOMOUS RESEARCH COMPLETE\n",
            "============================================================\n",
            "Symbol: AAPL\n",
            "Duration: 28.7s\n",
            "Quality Score: 0.87/1.00\n",
            "Memory Entries: 1\n",
            "All 4 Agent Functions: COMPLETE\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "ANALYZING ANOTHER STOCK (WITH MEMORY)\n",
            "============================================================\n",
            "\n",
            "############################################################\n",
            "# AUTONOMOUS RESEARCH: MSFT\n",
            "# LLM-Powered Multi-Agent System\n",
            "############################################################\n",
            "\n",
            "[1/4] Planning research...\n",
            "[2/4] Executing research...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 2: TOOL USAGE]\n",
            "Executing research for MSFT using real APIs...\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for MSFT using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is appropriate for MSFT due to its dominant position in the technology sector and significant market capitalization, which attract diverse investor interests. The focus on both quantitative financial metrics and qualitative insights from regulatory filings and market trends will provide a comprehensive view of MSFT's investment potential.\n",
            "\n",
            "\n",
            "[Data Collection Phase]\n",
            "Fetching from real financial APIs...\n",
            "  1. Yahoo Finance...\n",
            "     Got data for Microsoft Corporation\n",
            "  2. Yahoo Finance - News...\n",
            "     Got 3 news articles\n",
            "  3. Alpha Vantage...\n",
            "     Got company overview\n",
            "  4. FRED - Economic indicators...\n",
            "     Got economic data\n",
            "  5. SEC EDGAR...\n",
            "     Got SEC filings (CIK: 0000789019)\n",
            "\n",
            "[Agent Analysis Phase]\n",
            "Running LLM-powered specialized agents...\n",
            "  1. Market Data Agent...\n",
            "\n",
            "[Market Data Agent] Analyzing MSFT with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: bullish\n",
            "  2. Fundamentals Agent...\n",
            "\n",
            "[Fundamentals Agent] Analyzing MSFT fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  3. Economic Context Agent...\n",
            "\n",
            "[Economic Context Agent] Analyzing Technology sector economic context...\n",
            "  Economic analysis complete\n",
            "  4. Regulatory Agent...\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for MSFT...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "\n",
            "[Workflow Execution Phase]\n",
            "Running LLM-powered workflow patterns...\n",
            "  1. Prompt Chain Workflow...\n",
            "\n",
            "[Prompt Chain Workflow] Executing for MSFT...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 3.37s\n",
            "  2. Routing Workflow...\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the investment outlook for MSFT?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks for the investment outlook for M...\n",
            "  3. Evaluator-Optimizer Workflow...\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "\n",
            "Research execution complete!\n",
            "  Agents run: 4\n",
            "  Workflows executed: 3\n",
            "[3/4] Self-reflecting on quality...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 3: SELF-REFLECTION]\n",
            "Assessing research quality using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM for quality assessment...\n",
            "\n",
            "Self-reflection complete!\n",
            "  Overall Quality Score: 0.83/1.00\n",
            "  Strengths identified: 3\n",
            "  Improvements suggested: 3\n",
            "\n",
            "Top Strengths:\n",
            "  1. Diverse data sources utilized (Yahoo Finance, Alpha Vantage, FRED, SEC EDGAR) which provide a comprehensive view of MSFT's financials.\n",
            "  2. Multiple specialized agent analyses (market, fundamentals, economic, regulatory) enhance the overall understanding of the stock's performance.\n",
            "\n",
            "Key Improvements:\n",
            "  1. Implement a cross-validation step to ensure data accuracy across different sources.\n",
            "  2. Incorporate qualitative analysis to complement quantitative data, providing a more holistic view of MSFT's performance.\n",
            "[4/4] Learning from experience...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 4: LEARNING]\n",
            "Recording learnings for future improvement...\n",
            "============================================================\n",
            "\n",
            "Learning recorded!\n",
            "  Symbol: MSFT\n",
            "  Insights captured: 3\n",
            "  Quality score: 0.83\n",
            "  Total memory entries: 2\n",
            "\n",
            "============================================================\n",
            "AUTONOMOUS RESEARCH COMPLETE\n",
            "============================================================\n",
            "Symbol: MSFT\n",
            "Duration: 31.9s\n",
            "Quality Score: 0.83/1.00\n",
            "Memory Entries: 2\n",
            "All 4 Agent Functions: COMPLETE\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "RE-ANALYZING FIRST STOCK (LEARNING FROM PAST)\n",
            "============================================================\n",
            "\n",
            "############################################################\n",
            "# AUTONOMOUS RESEARCH: AAPL\n",
            "# LLM-Powered Multi-Agent System\n",
            "############################################################\n",
            "\n",
            " Found previous analysis of AAPL\n",
            "   Quality was: 0.87\n",
            "   Applying learned insights...\n",
            "\n",
            "[1/4] Planning research...\n",
            "[2/4] Executing research...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 2: TOOL USAGE]\n",
            "Executing research for AAPL using real APIs...\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for AAPL using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is appropriate for AAPL due to its significant market capitalization and influence within the technology sector. Analyzing both financial health and macroeconomic factors will provide a holistic view of AAPL’s potential, catering to investors' needs for thorough due diligence in a highly competitive and fast-evolving market.\n",
            "\n",
            "\n",
            "[Data Collection Phase]\n",
            "Fetching from real financial APIs...\n",
            "  1. Yahoo Finance...\n",
            "     Got data for Apple Inc.\n",
            "  2. Yahoo Finance - News...\n",
            "     Got 3 news articles\n",
            "  3. Alpha Vantage...\n",
            "     Got company overview\n",
            "  4. FRED - Economic indicators...\n",
            "     Got economic data\n",
            "  5. SEC EDGAR...\n",
            "     Got SEC filings (CIK: 0000320193)\n",
            "\n",
            "[Agent Analysis Phase]\n",
            "Running LLM-powered specialized agents...\n",
            "  1. Market Data Agent...\n",
            "\n",
            "[Market Data Agent] Analyzing AAPL with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: bullish\n",
            "  2. Fundamentals Agent...\n",
            "\n",
            "[Fundamentals Agent] Analyzing AAPL fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  3. Economic Context Agent...\n",
            "\n",
            "[Economic Context Agent] Analyzing Technology sector economic context...\n",
            "  Economic analysis complete\n",
            "  4. Regulatory Agent...\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for AAPL...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "\n",
            "[Workflow Execution Phase]\n",
            "Running LLM-powered workflow patterns...\n",
            "  1. Prompt Chain Workflow...\n",
            "\n",
            "[Prompt Chain Workflow] Executing for AAPL...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 3.13s\n",
            "  2. Routing Workflow...\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the investment outlook for AAPL?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks for the investment outlook for A...\n",
            "  3. Evaluator-Optimizer Workflow...\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.78\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "\n",
            "Research execution complete!\n",
            "  Agents run: 4\n",
            "  Workflows executed: 3\n",
            "[3/4] Self-reflecting on quality...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 3: SELF-REFLECTION]\n",
            "Assessing research quality using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM for quality assessment...\n",
            "\n",
            "Self-reflection complete!\n",
            "  Overall Quality Score: 0.85/1.00\n",
            "  Strengths identified: 3\n",
            "  Improvements suggested: 3\n",
            "\n",
            "Top Strengths:\n",
            "  1. Utilized multiple reputable data sources (Yahoo Finance, Alpha Vantage, FRED, SEC EDGAR) which enhances reliability.\n",
            "  2. Executed a variety of agent analyses (market, fundamentals, economic, regulatory) providing a comprehensive overview of AAPL.\n",
            "\n",
            "Key Improvements:\n",
            "  1. Cross-verify data points from multiple sources to ensure higher accuracy.\n",
            "  2. Incorporate qualitative analysis or expert opinions to provide deeper insights into the financial health of AAPL.\n",
            "[4/4] Learning from experience...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 4: LEARNING]\n",
            "Recording learnings for future improvement...\n",
            "============================================================\n",
            "\n",
            "Learning recorded!\n",
            "  Symbol: AAPL\n",
            "  Insights captured: 3\n",
            "  Quality score: 0.85\n",
            "  Total memory entries: 3\n",
            "  Previous analyses of AAPL: 1\n",
            "  Learning from past experience!\n",
            "\n",
            "============================================================\n",
            "AUTONOMOUS RESEARCH COMPLETE\n",
            "============================================================\n",
            "Symbol: AAPL\n",
            "Duration: 28.4s\n",
            "Quality Score: 0.85/1.00\n",
            "Memory Entries: 3\n",
            "All 4 Agent Functions: COMPLETE\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS:\n",
            "============================================================\n",
            "Total analyses: 3\n",
            "Unique stocks: 2\n",
            "\n",
            "Memory Contents:\n",
            "  1. AAPL: Quality 0.87\n",
            "  2. MSFT: Quality 0.83\n",
            "  3. AAPL: Quality 0.85\n",
            "\n",
            "============================================================\n",
            "ALL 4 AGENT FUNCTIONS WORKING! \n",
            "============================================================\n",
            "  1. Planning (LLM) \n",
            "  2. Tool Usage (APIs + Agents) \n",
            "  3. Self-Reflection (LLM) \n",
            "  4. Learning (Memory) \n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nTesting Complete Research Agent...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        print(\"OPENAI_API_KEY required\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        agent = InvestmentResearchAgent()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FULL AUTONOMOUS RESEARCH CYCLE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Analyze first stock\n",
        "        report1 = agent.conduct_research(\"AAPL\")\n",
        "\n",
        "        print(\"\\n\\n\" + \"=\"*60)\n",
        "        print(\"ANALYZING ANOTHER STOCK (WITH MEMORY)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Analyze second stock\n",
        "        report2 = agent.conduct_research(\"MSFT\")\n",
        "\n",
        "        print(\"\\n\\n\" + \"=\"*60)\n",
        "        print(\"RE-ANALYZING FIRST STOCK (LEARNING FROM PAST)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Re-analyze first stock (should show learning)\n",
        "        report3 = agent.conduct_research(\"AAPL\")\n",
        "\n",
        "        print(\"\\n\\n\" + \"=\"*60)\n",
        "        print(\"FINAL RESULTS:\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Total analyses: {len(agent.memory)}\")\n",
        "        print(f\"Unique stocks: {len(set(m.stock_symbol for m in agent.memory))}\")\n",
        "\n",
        "        print(\"\\nMemory Contents:\")\n",
        "        for i, mem in enumerate(agent.memory, 1):\n",
        "            print(f\"  {i}. {mem.stock_symbol}: Quality {mem.quality_scores['overall']:.2f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ALL 4 AGENT FUNCTIONS WORKING! \")\n",
        "        print(\"=\"*60)\n",
        "        print(\"  1. Planning (LLM) \")\n",
        "        print(\"  2. Tool Usage (APIs + Agents) \")\n",
        "        print(\"  3. Self-Reflection (LLM) \")\n",
        "        print(\"  4. Learning (Memory) \")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZXUd_JFQTWJ"
      },
      "source": [
        "## 8. Complete Autonomous Research Demonstration\n",
        "\n",
        "This section demonstrates the complete autonomous research cycle integrating all agent functions and workflow patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "dpPLx892QTWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae538e35-3894-4946-d521-71914bcdee2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Investment Research Agent initialized with LLM\n",
            "  Initializing API clients...\n",
            "  Initializing specialized agents...\n",
            "Market Data Agent initialized with LLM\n",
            "Fundamentals Agent initialized with LLM\n",
            "Economic Context Agent initialized with LLM\n",
            "Regulatory Agent initialized\n",
            "  Initializing workflows...\n",
            "Prompt Chain Workflow initialized with LLM\n",
            "Routing Workflow initialized with LLM\n",
            "Evaluator-Optimizer Workflow initialized with LLM\n",
            "Investment Research Agent fully initialized!\n",
            "\n",
            "================================================================================\n",
            "COMPLETE AUTONOMOUS RESEARCH DEMONSTRATION\n",
            "================================================================================\n",
            "\n",
            "############################################################\n",
            "# AUTONOMOUS RESEARCH: AMZN\n",
            "# LLM-Powered Multi-Agent System\n",
            "############################################################\n",
            "\n",
            "[1/4] Planning research...\n",
            "[2/4] Executing research...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 2: TOOL USAGE]\n",
            "Executing research for AMZN using real APIs...\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 1: PLANNING]\n",
            "Creating research plan for AMZN using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM to generate research plan...\n",
            "\n",
            "LLM-generated research plan created!\n",
            "  Objectives: 5\n",
            "  Analysis Steps: 7\n",
            "  Expected Outputs: 5\n",
            "\n",
            "Reasoning: This research plan is tailored for AMZN due to its significant role in the e-commerce sector and its extensive market capitalization. The combination of macroeconomic factors, regulatory scrutiny, and competitive dynamics makes a thorough analysis crucial for investors looking to navigate its volatile stock performance.\n",
            "\n",
            "\n",
            "[Data Collection Phase]\n",
            "Fetching from real financial APIs...\n",
            "  1. Yahoo Finance...\n",
            "     Got data for Amazon.com, Inc.\n",
            "  2. Yahoo Finance - News...\n",
            "     Got 3 news articles\n",
            "  3. Alpha Vantage...\n",
            "     Got company overview\n",
            "  4. FRED - Economic indicators...\n",
            "     Got economic data\n",
            "  5. SEC EDGAR...\n",
            "     Got SEC filings (CIK: 0001018724)\n",
            "\n",
            "[Agent Analysis Phase]\n",
            "Running LLM-powered specialized agents...\n",
            "  1. Market Data Agent...\n",
            "\n",
            "[Market Data Agent] Analyzing AMZN with LLM...\n",
            "  LLM analysis complete\n",
            "  Trend: neutral\n",
            "  2. Fundamentals Agent...\n",
            "\n",
            "[Fundamentals Agent] Analyzing AMZN fundamentals with LLM...\n",
            "  Fundamentals analysis complete\n",
            "  3. Economic Context Agent...\n",
            "\n",
            "[Economic Context Agent] Analyzing Consumer Cyclical sector economic context...\n",
            "  Economic analysis complete\n",
            "  4. Regulatory Agent...\n",
            "\n",
            "[Regulatory Agent] Analyzing regulatory status for AMZN...\n",
            "  Regulatory analysis complete\n",
            "    Status: Current\n",
            "\n",
            "[Workflow Execution Phase]\n",
            "Running LLM-powered workflow patterns...\n",
            "  1. Prompt Chain Workflow...\n",
            "\n",
            "[Prompt Chain Workflow] Executing for AMZN...\n",
            "  [Step 1/5] Ingesting data...\n",
            "  [Step 2/5] Preprocessing...\n",
            "  [Step 3/5] Classifying...\n",
            "  [Step 4/5] Extracting insights with LLM...\n",
            "  [Step 5/5] Synthesizing summary with LLM...\n",
            "  Workflow complete in 2.79s\n",
            "  2. Routing Workflow...\n",
            "\n",
            "[Routing Workflow] Routing query with LLM...\n",
            "  Query: What's the investment outlook for AMZN?...\n",
            "  Routed to: MarketDataAgent\n",
            "  Reasoning: The query specifically asks for the investment outlook for A...\n",
            "  3. Evaluator-Optimizer Workflow...\n",
            "\n",
            "[Evaluator-Optimizer Workflow] Starting optimization...\n",
            "  [Iteration 1/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 2/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "    Optimizing...\n",
            "  [Iteration 3/3] Evaluating...\n",
            "    Quality score: 0.75\n",
            "\n",
            "Research execution complete!\n",
            "  Agents run: 4\n",
            "  Workflows executed: 3\n",
            "[3/4] Self-reflecting on quality...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 3: SELF-REFLECTION]\n",
            "Assessing research quality using LLM...\n",
            "============================================================\n",
            "\n",
            "  Calling LLM for quality assessment...\n",
            "\n",
            "Self-reflection complete!\n",
            "  Overall Quality Score: 0.87/1.00\n",
            "  Strengths identified: 3\n",
            "  Improvements suggested: 3\n",
            "\n",
            "Top Strengths:\n",
            "  1. Diverse data sources utilized, including reputable platforms like Yahoo Finance and SEC EDGAR, enhancing the credibility of the analysis.\n",
            "  2. Multiple agent analyses completed (market, fundamentals, economic, regulatory) provide a well-rounded view of AMZN's performance and potential.\n",
            "\n",
            "Key Improvements:\n",
            "  1. Increase the number of specialized agents to include additional perspectives, such as technical analysis or sentiment analysis, to enrich the research output.\n",
            "  2. Provide more detailed documentation on the results of the workflow patterns executed, including performance metrics and insights gained from each pattern.\n",
            "[4/4] Learning from experience...\n",
            "\n",
            "============================================================\n",
            "[AGENT FUNCTION 4: LEARNING]\n",
            "Recording learnings for future improvement...\n",
            "============================================================\n",
            "\n",
            "Learning recorded!\n",
            "  Symbol: AMZN\n",
            "  Insights captured: 3\n",
            "  Quality score: 0.87\n",
            "  Total memory entries: 1\n",
            "\n",
            "============================================================\n",
            "AUTONOMOUS RESEARCH COMPLETE\n",
            "============================================================\n",
            "Symbol: AMZN\n",
            "Duration: 27.8s\n",
            "Quality Score: 0.87/1.00\n",
            "Memory Entries: 1\n",
            "All 4 Agent Functions: COMPLETE\n",
            "============================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FINAL RESEARCH REPORT\n",
            "================================================================================\n",
            "\n",
            "Symbol: AMZN\n",
            "Analysis Timestamp: 2025-10-19T22:55:28.155249\n",
            "\n",
            "============================================================\n",
            "QUALITY METRICS\n",
            "============================================================\n",
            "Overall Quality Score: 0.87\n",
            "\n",
            "Workflow Execution:\n",
            "\n",
            "============================================================\n",
            "ANALYSIS STRENGTHS\n",
            "============================================================\n",
            " - Diverse data sources utilized, including reputable platforms like Yahoo Finance and SEC EDGAR, enhancing the credibility of the analysis.\n",
            " - Multiple agent analyses completed (market, fundamentals, economic, regulatory) provide a well-rounded view of AMZN's performance and potential.\n",
            " - The use of advanced workflow patterns (prompt_chain, routing, evaluator_optimizer) indicates a structured and systematic approach to data processing.\n",
            "\n",
            "============================================================\n",
            "AREAS FOR IMPROVEMENT\n",
            "============================================================\n",
            " -  Limited number of specialized agents (only 4) may not capture the full spectrum of insights available for AMZN, potentially missing nuanced analyses.\n",
            " -  While workflow patterns were executed, the details on their effectiveness and outcomes are lacking, making it difficult to assess their impact.\n",
            "\n",
            "============================================================\n",
            "IMPROVEMENT SUGGESTIONS\n",
            "============================================================\n",
            "  - Increase the number of specialized agents to include additional perspectives, such as technical analysis or sentiment analysis, to enrich the research output.\n",
            "  - Provide more detailed documentation on the results of the workflow patterns executed, including performance metrics and insights gained from each pattern.\n",
            "  - Consider integrating qualitative data or expert opinions to complement quantitative findings, which could enhance the depth of analysis.\n",
            "\n",
            "============================================================\n",
            "LEARNING & MEMORY\n",
            "============================================================\n",
            "Total Analyses Conducted: 1\n",
            "Previous Analysis Available: False\n"
          ]
        }
      ],
      "source": [
        "# Create a fresh agent for complete demonstration\n",
        "demo_agent = InvestmentResearchAgent()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPLETE AUTONOMOUS RESEARCH DEMONSTRATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "demo_symbol = \"AMZN\"\n",
        "\n",
        "# Conduct complete autonomous research\n",
        "final_report = demo_agent.conduct_research(demo_symbol)\n",
        "\n",
        "# Display comprehensive results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL RESEARCH REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nSymbol: {demo_symbol}\")\n",
        "print(f\"Analysis Timestamp: {datetime.now().isoformat()}\")\n",
        "\n",
        "# Research summary\n",
        "reflection = final_report.get('self_reflection', {})\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"QUALITY METRICS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Overall Quality Score: {reflection.get('overall_quality_score', 0):.2f}\")\n",
        "\n",
        "qa = reflection.get('quality_assessment', {})\n",
        "print(f\"\\nWorkflow Execution:\")\n",
        "if 'prompt_chain' in qa:\n",
        "    print(f\"  Prompt Chain: {qa['prompt_chain'].get('completeness', 0):.2f}\")\n",
        "if 'routing' in qa:\n",
        "    print(f\"  Routing: {qa['routing'].get('routes_completed', 0)}/4 routes\")\n",
        "if 'evaluator_optimizer' in qa:\n",
        "    print(f\"  Evaluator-Optimizer: {qa['evaluator_optimizer'].get('final_score', 0):.2f}\")\n",
        "    print(f\"  Optimization Iterations: {qa['evaluator_optimizer'].get('iterations', 0)}\")\n",
        "\n",
        "# Display strengths and recommendations\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ANALYSIS STRENGTHS\")\n",
        "print(f\"{'='*60}\")\n",
        "for strength in reflection.get('strengths', []):\n",
        "    print(f\" - {strength}\")\n",
        "\n",
        "if reflection.get('weaknesses', []):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"AREAS FOR IMPROVEMENT\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for weakness in reflection.get('weaknesses', []):\n",
        "        print(f\" -  {weakness}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"IMPROVEMENT SUGGESTIONS\")\n",
        "print(f\"{'='*60}\")\n",
        "for suggestion in reflection.get('improvement_suggestions', []):\n",
        "    print(f\"  - {suggestion}\")\n",
        "\n",
        "# Memory status\n",
        "memory_status = final_report.get('memory_status', {})\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"LEARNING & MEMORY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total Analyses Conducted: {memory_status.get('total_analyses', 0)}\")\n",
        "print(f\"Previous Analysis Available: {memory_status.get('previous_analysis_available', False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gigMm7IHQTWZ"
      },
      "source": [
        "## 9. Conclusion & Project Requirements Summary\n",
        "\n",
        "### Project Requirements Fulfilled\n",
        "\n",
        "#### Agent Functions (33.8%)\n",
        "1. **Planning**: Autonomous research plan creation based on stock symbol\n",
        "2. **Tool Usage**: Dynamic coordination of 4 APIs and 4 specialized agents\n",
        "3. **Self-Reflection**: Quality assessment with scoring and improvement identification\n",
        "4. **Learning**: Memory persistence across runs with continuous improvement\n",
        "\n",
        "#### Workflow Patterns (33.8%)\n",
        "1. **Prompt Chaining**: Ingest → Preprocess → Classify → Extract → Summarize\n",
        "2. **Routing**: Intelligent direction to specialized agents (Market, Fundamentals, Economic, Regulatory)\n",
        "3. **Evaluator-Optimizer**: Iterative quality improvement through Generate → Evaluate → Optimize\n",
        "\n",
        "#### Code Quality (32.4%)\n",
        "- Clean, modular, PEP8-compliant Python code\n",
        "- Comprehensive documentation and comments\n",
        "- GitHub integration for version control\n",
        "- Professional data structures and error handling\n",
        "\n",
        "### Data Sources Integrated\n",
        "1. **Yahoo Finance**: Stock prices, financials, historical data\n",
        "2. **Alpha Vantage**: Real-time quotes, company overviews\n",
        "3. **FRED**: Economic indicators (interest rates, employment, inflation)\n",
        "4. **SEC EDGAR**: Regulatory filings (10-K, 10-Q)\n",
        "\n",
        "### Key Achievements\n",
        "- Fully autonomous investment research agent\n",
        "- Multi-agent coordination and specialization\n",
        "- Self-improving system through reflection and learning\n",
        "- Professional-grade code architecture\n",
        "- Comprehensive testing and validation\n",
        "- Real-world financial data integration\n",
        "\n",
        "### Future Enhancements\n",
        "- Integration with live API keys for real-time data\n",
        "- Enhanced natural language generation for reports\n",
        "- Additional specialized agents (technical analysis, sentiment analysis)\n",
        "- Portfolio-level analysis capabilities\n",
        "- Advanced visualization dashboard\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}